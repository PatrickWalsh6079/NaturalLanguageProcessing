{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2e232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting started to process a text example\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6955c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carroll-alice.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec98fae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33494\n",
      "['[', 'alice', \"'s\", 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', '1865', ']', 'chapter', 'i', '.', 'down', 'the', 'rabbit-hole', 'alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'and\", 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', \"'\", 'thought', 'alice', \"'without\", 'pictures', 'or', 'conversation', '?', \"'\", 'so', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', ')', ',']\n"
     ]
    }
   ],
   "source": [
    "# get the text of the book Emma from the Gutenberg corpus, tokenize it,\n",
    "#   and reduce the tokens to lowercase.\n",
    "file = nltk.corpus.gutenberg.fileids()[7]\n",
    "alice = nltk.corpus.gutenberg.raw(file)\n",
    "alicetokens = nltk.word_tokenize(alice) \n",
    "alicewords = [w.lower() for w in alicetokens] \n",
    "# show some of the words\n",
    "print(len(alicewords))\n",
    "print(alicewords[:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cf5527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bible-kjv.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210c29b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946812\n",
      "['[', 'the', 'king', 'james', 'bible', ']', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', ':', 'called', 'genesis', '1:1', 'in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.', '1:2', 'and', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', '.', 'and', 'the', 'spirit', 'of', 'god', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.', '1:3', 'and', 'god', 'said', ',', 'let', 'there', 'be', 'light', ':', 'and', 'there', 'was', 'light', '.', '1:4', 'and', 'god', 'saw', 'the', 'light', ',', 'that', 'it', 'was', 'good', ':', 'and', 'god', 'divided', 'the', 'light', 'from', 'the', 'darkness', '.', '1:5', 'and', 'god', 'called', 'the', 'light']\n"
     ]
    }
   ],
   "source": [
    "# get the text of the book Emma from the Gutenberg corpus, tokenize it,\n",
    "#   and reduce the tokens to lowercase.\n",
    "file = nltk.corpus.gutenberg.fileids()[3]\n",
    "bible = nltk.corpus.gutenberg.raw(file)\n",
    "bibletokens = nltk.word_tokenize(bible) \n",
    "biblewords = [w.lower() for w in bibletokens] \n",
    "# show some of the words\n",
    "print(len(biblewords))\n",
    "print(biblewords[:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb437cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 70573\n",
      "the \t 64023\n",
      "and \t 51696\n",
      "of \t 34670\n",
      ". \t 26202\n",
      "to \t 13580\n",
      "that \t 12912\n",
      ": \t 12706\n",
      "in \t 12667\n",
      "he \t 10419\n",
      "; \t 10139\n",
      "shall \t 9838\n",
      "unto \t 8997\n",
      "for \t 8971\n",
      "i \t 8854\n",
      "his \t 8473\n",
      "a \t 8177\n",
      "lord \t 7944\n",
      "they \t 7376\n",
      "be \t 7013\n",
      "is \t 6989\n",
      "not \t 6780\n",
      "him \t 6659\n",
      "them \t 6430\n",
      "it \t 6129\n",
      "with \t 6012\n",
      "all \t 5620\n",
      "thou \t 5474\n",
      "thy \t 4600\n",
      "was \t 4522\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(biblewords)\n",
    "\n",
    "# print the top 30 tokens by frequency\n",
    "nitems = ndist.most_common(30)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59fc34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'the', 'king', 'james', 'bible', ']', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', ':', 'called']\n",
      "[('[', 'the'), ('the', 'king'), ('king', 'james'), ('james', 'bible'), ('bible', ']'), (']', 'the'), ('the', 'old'), ('old', 'testament'), ('testament', 'of'), ('of', 'the'), ('the', 'king'), ('king', 'james'), ('james', 'bible'), ('bible', 'the'), ('the', 'first'), ('first', 'book'), ('book', 'of'), ('of', 'moses'), ('moses', ':'), (':', 'called')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "biblebigrams = list(nltk.bigrams(biblewords))\n",
    "print(biblewords[:21])\n",
    "print(biblebigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f779ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "((',', 'and'), 0.026345251221995495)\n",
      "((',', 'and'), 0.026345251221995495)\n",
      "(('of', 'the'), 0.01218932586405749)\n",
      "(('the', 'lord'), 0.007410129994127662)\n",
      "(('and', 'the'), 0.006616941906101739)\n",
      "(('in', 'the'), 0.005312564690772825)\n",
      "((';', 'and'), 0.0033966616392694642)\n",
      "((':', 'and'), 0.0031991567491751268)\n",
      "((',', 'that'), 0.0031590220656265446)\n",
      "(('and', 'he'), 0.002946730713172203)\n",
      "((',', 'the'), 0.0026013611994778266)\n",
      "(('shall', 'be'), 0.0025992488477121116)\n",
      "(('to', 'the'), 0.002272890499909169)\n",
      "(('all', 'the'), 0.002258104037549165)\n",
      "(('and', 'they'), 0.0022031828916405792)\n",
      "(('him', ','), 0.0021514302733805653)\n",
      "(('unto', 'the'), 0.0021461493939662784)\n",
      "(('i', 'will'), 0.0020225768156719604)\n",
      "((',', 'which'), 0.0018937233579633549)\n",
      "(('lord', ','), 0.0018050045838033317)\n",
      "(('of', 'israel'), 0.0017902181214433277)\n",
      "(('said', ','), 0.0017743754832004663)\n",
      "(('for', 'the'), 0.001765926076137607)\n",
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "((':', 'for'), 0.0017236790408233103)\n",
      "(('the', 'king'), 0.001713117281994736)\n",
      "((',', 'i'), 0.001700443171400447)\n",
      "(('them', ','), 0.0016983308196347321)\n",
      "(('son', 'of'), 0.0016909375884547303)\n",
      "(('out', 'of'), 0.0015863761760518456)\n",
      "(('the', 'son'), 0.0015842638242861307)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(biblewords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "# scored is a list of bigram pairs with their score\n",
    "print(type(scored))\n",
    "first = scored[0]\n",
    "print(type(first))\n",
    "print(first)\n",
    "\n",
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801066bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.01218932586405749)\n",
      "(('the', 'lord'), 0.007410129994127662)\n",
      "(('and', 'the'), 0.006616941906101739)\n",
      "(('in', 'the'), 0.005312564690772825)\n",
      "(('and', 'he'), 0.002946730713172203)\n",
      "(('shall', 'be'), 0.0025992488477121116)\n",
      "(('to', 'the'), 0.002272890499909169)\n",
      "(('all', 'the'), 0.002258104037549165)\n",
      "(('and', 'they'), 0.0022031828916405792)\n",
      "(('unto', 'the'), 0.0021461493939662784)\n",
      "(('i', 'will'), 0.0020225768156719604)\n",
      "(('of', 'israel'), 0.0017902181214433277)\n",
      "(('for', 'the'), 0.001765926076137607)\n",
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "(('the', 'king'), 0.001713117281994736)\n",
      "(('son', 'of'), 0.0016909375884547303)\n",
      "(('out', 'of'), 0.0015863761760518456)\n",
      "(('the', 'son'), 0.0015842638242861307)\n",
      "(('the', 'children'), 0.0014997697536575372)\n",
      "(('children', 'of'), 0.0014680844771718146)\n",
      "(('the', 'land'), 0.00133078161240035)\n",
      "(('and', 'i'), 0.0013255007329860628)\n",
      "(('thou', 'shalt'), 0.0013202198535717756)\n",
      "(('the', 'people'), 0.0012906469288517677)\n",
      "(('the', 'house'), 0.0012378381347088968)\n",
      "(('from', 'the'), 0.0012219954964660354)\n",
      "(('unto', 'him'), 0.0011913663958631703)\n",
      "(('of', 'his'), 0.0011723552299717367)\n",
      "(('i', 'have'), 0.0011206026117117232)\n",
      "(('and', 'all'), 0.001107928501117434)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c34d8409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "(('thou', 'shalt'), 0.0013202198535717756)\n",
      "(('thou', 'hast'), 0.000811143078034499)\n",
      "(('ye', 'shall'), 0.0007995251433230673)\n",
      "(('lord', 'god'), 0.0005756158561572942)\n",
      "(('unto', 'thee'), 0.0005291441173115676)\n",
      "(('thus', 'saith'), 0.0004689420919886947)\n",
      "(('say', 'unto'), 0.00042035800137725336)\n",
      "(('shall', 'come'), 0.00041824564961153853)\n",
      "(('thy', 'god'), 0.0003770547901800991)\n",
      "(('thou', 'art'), 0.0003358639307486597)\n",
      "(('every', 'one'), 0.0003326954031000875)\n",
      "(('lord', 'thy'), 0.00032318982015437067)\n",
      "(('every', 'man'), 0.0003094595336772242)\n",
      "(('lord', 'hath'), 0.0003041786542629371)\n",
      "(('spake', 'unto'), 0.00028622366425436093)\n",
      "(('shalt', 'thou'), 0.00027249337777721447)\n",
      "(('lord', 'said'), 0.00023341487011148992)\n",
      "(('let', 'us'), 0.0002270778148143454)\n",
      "(('unto', 'moses'), 0.0002165160559857712)\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "nltk.download('stopwords')\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "\n",
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06869150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.026345251221995495)\n",
      "(('of', 'the'), 0.01218932586405749)\n",
      "(('the', 'lord'), 0.007410129994127662)\n",
      "(('and', 'the'), 0.006616941906101739)\n",
      "(('in', 'the'), 0.005312564690772825)\n",
      "((';', 'and'), 0.0033966616392694642)\n",
      "((':', 'and'), 0.0031991567491751268)\n",
      "((',', 'that'), 0.0031590220656265446)\n",
      "(('and', 'he'), 0.002946730713172203)\n",
      "((',', 'the'), 0.0026013611994778266)\n",
      "(('shall', 'be'), 0.0025992488477121116)\n",
      "(('to', 'the'), 0.002272890499909169)\n",
      "(('all', 'the'), 0.002258104037549165)\n",
      "(('and', 'they'), 0.0022031828916405792)\n",
      "(('him', ','), 0.0021514302733805653)\n",
      "(('unto', 'the'), 0.0021461493939662784)\n",
      "(('i', 'will'), 0.0020225768156719604)\n",
      "((',', 'which'), 0.0018937233579633549)\n",
      "(('lord', ','), 0.0018050045838033317)\n",
      "(('of', 'israel'), 0.0017902181214433277)\n"
     ]
    }
   ],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(biblewords)\n",
    "finder2.apply_freq_filter(2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79767289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.01218932586405749)\n",
      "(('the', 'lord'), 0.007410129994127662)\n",
      "(('and', 'the'), 0.006616941906101739)\n",
      "(('in', 'the'), 0.005312564690772825)\n",
      "(('and', 'he'), 0.002946730713172203)\n",
      "(('shall', 'be'), 0.0025992488477121116)\n",
      "(('to', 'the'), 0.002272890499909169)\n",
      "(('all', 'the'), 0.002258104037549165)\n",
      "(('and', 'they'), 0.0022031828916405792)\n",
      "(('him', ','), 0.0021514302733805653)\n",
      "(('unto', 'the'), 0.0021461493939662784)\n",
      "(('lord', ','), 0.0018050045838033317)\n",
      "(('of', 'israel'), 0.0017902181214433277)\n",
      "(('said', ','), 0.0017743754832004663)\n",
      "(('for', 'the'), 0.001765926076137607)\n",
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "(('the', 'king'), 0.001713117281994736)\n",
      "(('them', ','), 0.0016983308196347321)\n",
      "(('son', 'of'), 0.0016909375884547303)\n",
      "(('out', 'of'), 0.0015863761760518456)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter on both words of the ngram\n",
    "finder2.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496ecb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('anathema', 'maranatha'), 19.852718465501717)\n",
      "(('appii', 'forum'), 19.852718465501717)\n",
      "(('ashteroth', 'karnaim'), 19.852718465501717)\n",
      "(('barbed', 'irons'), 19.852718465501717)\n",
      "(('changeable', 'suits'), 19.852718465501717)\n",
      "(('dromedary', 'traversing'), 19.852718465501717)\n",
      "(('equally', 'distant'), 19.852718465501717)\n",
      "(('eubulus', 'greeteth'), 19.852718465501717)\n",
      "(('fared', 'sumptuously'), 19.852718465501717)\n",
      "(('grandmother', 'lois'), 19.852718465501717)\n",
      "((\"herod's\", 'jurisdiction'), 19.852718465501717)\n",
      "(('infallible', 'proofs'), 19.852718465501717)\n",
      "(('je', 'hoshaphat'), 19.852718465501717)\n",
      "(('monthly', 'prognosticators'), 19.852718465501717)\n",
      "(('narrowed', 'rests'), 19.852718465501717)\n",
      "(('sergius', 'paulus'), 19.852718465501717)\n",
      "(('sticketh', 'closer'), 19.852718465501717)\n",
      "(('talitha', 'cumi'), 19.852718465501717)\n",
      "(('tottering', 'fence'), 19.852718465501717)\n",
      "(('unequally', 'yoked'), 19.852718465501717)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(biblewords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18061571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('untempered', 'morter'), 16.39328684686442)\n",
      "(('cock', 'crew'), 16.26775596478056)\n",
      "(('gray', 'hairs'), 15.945827869893197)\n",
      "(('cock', 'crow'), 15.782329137610319)\n",
      "(('filthy', 'lucre'), 15.502221218417583)\n",
      "(('skins', 'dyed'), 14.782329137610319)\n",
      "(('ill', 'favoured'), 14.72343544855675)\n",
      "(('judas', 'iscariot'), 14.518817728948278)\n",
      "(('curious', 'girdle'), 14.28286285717077)\n",
      "(('brook', 'kidron'), 14.277809629444484)\n",
      "(('measuring', 'reed'), 14.156247649563568)\n",
      "(('divers', 'colours'), 14.058302599151611)\n",
      "(('mary', 'magdalene'), 13.972300081254389)\n",
      "(('wreathen', 'chains'), 13.643265099872766)\n",
      "(('dyed', 'red'), 13.639371183768276)\n",
      "(('fiery', 'furnace'), 13.623899775005835)\n",
      "(('committeth', 'adultery'), 13.604790952058131)\n",
      "(('earthen', 'vessel'), 13.592190915278495)\n",
      "(('golden', 'spoon'), 13.545289940309468)\n",
      "(('bright', 'spot'), 13.520806282041733)\n",
      "(('tenth', 'deals'), 13.512868462617092)\n",
      "(('bottomless', 'pit'), 13.393286846864417)\n",
      "(('familiar', 'spirits'), 13.329156509444704)\n",
      "(('solemn', 'feasts'), 13.316665565261506)\n",
      "(('walketh', 'uprightly'), 13.232132055049838)\n",
      "(('linen', 'breeches'), 13.152278747360624)\n",
      "(('twined', 'linen'), 13.152278747360624)\n",
      "(('straitly', 'charged'), 13.042789599780285)\n",
      "(('dearly', 'beloved'), 13.032539503086529)\n",
      "(('wave', 'breast'), 13.004721558946766)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5775c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
