{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c2b499",
   "metadata": {},
   "source": [
    "# Choosing the data\n",
    "Choose existing large documents from NLTK or the Gutenberg collection on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "da2e232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting started to process a text example\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6955c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carroll-alice.txt'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5cf5527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bible-kjv.txt'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9b120",
   "metadata": {},
   "source": [
    "# Analyze the text\n",
    "Examine the text in the documents that you chose and decide how to process the words, i.e. decide on tokenization and whether to use all lowercase, stopwords, or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec98fae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33494\n",
      "['[', 'alice', \"'s\", 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', '1865', ']', 'chapter', 'i', '.', 'down', 'the', 'rabbit-hole', 'alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'and\", 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', \"'\", 'thought', 'alice', \"'without\", 'pictures', 'or', 'conversation', '?', \"'\", 'so', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', ')', ',']\n"
     ]
    }
   ],
   "source": [
    "file1 = nltk.corpus.gutenberg.fileids()[7]\n",
    "alice = nltk.corpus.gutenberg.raw(file1)\n",
    "alicetokens = nltk.word_tokenize(alice) \n",
    "alicewords = [w.lower() for w in alicetokens] \n",
    "# show some of the words\n",
    "print(len(alicewords))\n",
    "print(alicewords[:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "210c29b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946812\n",
      "['[', 'the', 'king', 'james', 'bible', ']', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', ':', 'called', 'genesis', '1:1', 'in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.', '1:2', 'and', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', '.', 'and', 'the', 'spirit', 'of', 'god', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.', '1:3', 'and', 'god', 'said', ',', 'let', 'there', 'be', 'light', ':', 'and', 'there', 'was', 'light', '.', '1:4', 'and', 'god', 'saw', 'the', 'light', ',', 'that', 'it', 'was', 'good', ':', 'and', 'god', 'divided', 'the', 'light', 'from', 'the', 'darkness', '.', '1:5', 'and', 'god', 'called', 'the', 'light']\n"
     ]
    }
   ],
   "source": [
    "file2 = nltk.corpus.gutenberg.fileids()[3]\n",
    "bible = nltk.corpus.gutenberg.raw(file2)\n",
    "bibletokens = nltk.word_tokenize(bible) \n",
    "biblewords = [w.lower() for w in bibletokens] \n",
    "# show some of the words\n",
    "print(len(biblewords))\n",
    "print(biblewords[:110])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6945af",
   "metadata": {},
   "source": [
    "# List the top 50 words by frequency (normalized by the length of the document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d0737d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice in Wonderland top 50 words:\n",
      ", \t 2418\n",
      "the \t 1616\n",
      "' \t 1309\n",
      ". \t 975\n",
      "and \t 810\n",
      "to \t 720\n",
      "a \t 631\n",
      "she \t 544\n",
      "it \t 539\n",
      "i \t 533\n",
      "of \t 499\n",
      "said \t 462\n",
      "! \t 450\n",
      "alice \t 396\n",
      "was \t 366\n",
      "in \t 359\n",
      "you \t 356\n",
      "that \t 284\n",
      "-- \t 264\n",
      "as \t 256\n",
      "her \t 248\n",
      ": \t 233\n",
      "at \t 209\n",
      "n't \t 204\n",
      "? \t 202\n",
      "'s \t 194\n",
      "; \t 194\n",
      "on \t 191\n",
      "had \t 184\n",
      "with \t 179\n",
      "all \t 178\n",
      "be \t 148\n",
      "for \t 146\n",
      "so \t 144\n",
      "very \t 139\n",
      "not \t 135\n",
      "they \t 135\n",
      "but \t 131\n",
      "this \t 131\n",
      "little \t 128\n",
      "do \t 125\n",
      "he \t 117\n",
      "is \t 113\n",
      "out \t 113\n",
      "what \t 103\n",
      "down \t 102\n",
      "one \t 99\n",
      "up \t 97\n",
      "his \t 95\n",
      "about \t 94\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(alicewords)\n",
    "\n",
    "# print the top 50 tokens by frequency\n",
    "nitems_alice = ndist.most_common(50)\n",
    "print('Alice in Wonderland top 50 words:')\n",
    "for item in nitems_alice:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fb437cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KJV Bible top 50 words:\n",
      ", \t 70573\n",
      "the \t 64023\n",
      "and \t 51696\n",
      "of \t 34670\n",
      ". \t 26202\n",
      "to \t 13580\n",
      "that \t 12912\n",
      ": \t 12706\n",
      "in \t 12667\n",
      "he \t 10419\n",
      "; \t 10139\n",
      "shall \t 9838\n",
      "unto \t 8997\n",
      "for \t 8971\n",
      "i \t 8854\n",
      "his \t 8473\n",
      "a \t 8177\n",
      "lord \t 7944\n",
      "they \t 7376\n",
      "be \t 7013\n",
      "is \t 6989\n",
      "not \t 6780\n",
      "him \t 6659\n",
      "them \t 6430\n",
      "it \t 6129\n",
      "with \t 6012\n",
      "all \t 5620\n",
      "thou \t 5474\n",
      "thy \t 4600\n",
      "was \t 4522\n",
      "god \t 4467\n",
      "which \t 4413\n",
      "my \t 4368\n",
      "me \t 4096\n",
      "said \t 3999\n",
      "but \t 3992\n",
      "ye \t 3983\n",
      "their \t 3942\n",
      "have \t 3904\n",
      "will \t 3836\n",
      "thee \t 3826\n",
      "from \t 3642\n",
      "as \t 3520\n",
      "? \t 3297\n",
      "are \t 2950\n",
      "when \t 2834\n",
      "this \t 2785\n",
      "out \t 2775\n",
      "were \t 2772\n",
      "upon \t 2748\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(biblewords)\n",
    "\n",
    "# print the top 50 tokens by frequency\n",
    "nitems = ndist.most_common(50)\n",
    "print('KJV Bible top 50 words:')\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9a9a1",
   "metadata": {},
   "source": [
    "# Additional preprocessing - remove stopwords and non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "88160cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.collocations import *\n",
    "\n",
    "def remove_non_alpha(word_list):\n",
    "    \n",
    "    # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    new_word_list = []\n",
    "    for word in word_list:\n",
    "        if not (pattern.match(word)):\n",
    "            new_word_list.append(word)\n",
    "    return new_word_list\n",
    "\n",
    "\n",
    "def remove_stopwords(word_list):\n",
    "    # get a list of stopwords from nltk\n",
    "    nltk.download('stopwords')\n",
    "    nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "\n",
    "    stopwords = nltkstopwords + morestopwords\n",
    "    new_word_list = []\n",
    "    for word in word_list:\n",
    "        if word not in stopwords:\n",
    "            new_word_list.append(word)\n",
    "    return new_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "014264b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "alice_processed = remove_non_alpha(alicewords)\n",
    "alice_processed = remove_stopwords(alice_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8bdb7e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bible_processed = remove_non_alpha(biblewords)\n",
    "bible_processed = remove_stopwords(bible_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c865aa0",
   "metadata": {},
   "source": [
    "# Top 50 words after additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c92e23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice in Wonderland top 50 words (after additional preprocessing):\n",
      "said \t 462\n",
      "alice \t 396\n",
      "little \t 128\n",
      "one \t 99\n",
      "know \t 88\n",
      "like \t 85\n",
      "went \t 83\n",
      "queen \t 75\n",
      "thought \t 74\n",
      "time \t 68\n",
      "see \t 67\n",
      "king \t 62\n",
      "began \t 58\n",
      "turtle \t 58\n",
      "'and \t 56\n",
      "hatter \t 56\n",
      "mock \t 56\n",
      "quite \t 55\n",
      "'it \t 55\n",
      "gryphon \t 54\n",
      "think \t 53\n",
      "way \t 53\n",
      "much \t 51\n",
      "say \t 51\n",
      "first \t 50\n",
      "head \t 50\n",
      "'you \t 50\n",
      "thing \t 49\n",
      "go \t 48\n",
      "voice \t 48\n",
      "rabbit \t 47\n",
      "looked \t 45\n",
      "never \t 45\n",
      "got \t 45\n",
      "get \t 44\n",
      "mouse \t 42\n",
      "duchess \t 42\n",
      "round \t 41\n",
      "came \t 40\n",
      "tone \t 40\n",
      "dormouse \t 40\n",
      "great \t 39\n",
      "'but \t 39\n",
      "'what \t 38\n",
      "well \t 37\n",
      "back \t 37\n",
      "two \t 37\n",
      "cat \t 36\n",
      "march \t 34\n",
      "large \t 33\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist_processed = FreqDist(alice_processed)\n",
    "\n",
    "# print the top 50 tokens by frequency\n",
    "nitems = ndist_processed.most_common(50)\n",
    "print('Alice in Wonderland top 50 words (after additional preprocessing):')\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eed5268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bible top 50 words (after additional preprocessing):\n",
      "shall \t 9838\n",
      "unto \t 8997\n",
      "lord \t 7944\n",
      "thou \t 5474\n",
      "thy \t 4600\n",
      "god \t 4467\n",
      "said \t 3999\n",
      "ye \t 3983\n",
      "thee \t 3826\n",
      "upon \t 2748\n",
      "man \t 2728\n",
      "israel \t 2571\n",
      "king \t 2506\n",
      "son \t 2388\n",
      "hath \t 2264\n",
      "people \t 2143\n",
      "came \t 2093\n",
      "house \t 2024\n",
      "come \t 1971\n",
      "one \t 1969\n",
      "children \t 1818\n",
      "also \t 1769\n",
      "day \t 1740\n",
      "land \t 1718\n",
      "men \t 1673\n",
      "shalt \t 1616\n",
      "let \t 1511\n",
      "go \t 1492\n",
      "hand \t 1466\n",
      "us \t 1448\n",
      "saying \t 1445\n",
      "made \t 1405\n",
      "went \t 1400\n",
      "even \t 1393\n",
      "behold \t 1326\n",
      "saith \t 1262\n",
      "therefore \t 1237\n",
      "every \t 1236\n",
      "things \t 1162\n",
      "father \t 1111\n",
      "sons \t 1090\n",
      "hast \t 1070\n",
      "david \t 1058\n",
      "make \t 1056\n",
      "say \t 1056\n",
      "may \t 1027\n",
      "earth \t 987\n",
      "jesus \t 983\n",
      "great \t 962\n",
      "name \t 955\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist_processed = FreqDist(bible_processed)\n",
    "\n",
    "# print the top 50 tokens by frequency\n",
    "nitems = ndist_processed.most_common(50)\n",
    "print('Bible top 50 words (after additional preprocessing):')\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cf2b1",
   "metadata": {},
   "source": [
    "# List the top 50 bigrams by frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7c98ebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'alice', \"'s\", 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', '1865', ']', 'chapter', 'i', '.', 'down', 'the', 'rabbit-hole', 'alice', 'was', 'beginning', 'to']\n",
      "[('[', 'alice'), ('alice', \"'s\"), (\"'s\", 'adventures'), ('adventures', 'in'), ('in', 'wonderland'), ('wonderland', 'by'), ('by', 'lewis'), ('lewis', 'carroll'), ('carroll', '1865'), ('1865', ']'), (']', 'chapter'), ('chapter', 'i'), ('i', '.'), ('.', 'down'), ('down', 'the'), ('the', 'rabbit-hole'), ('rabbit-hole', 'alice'), ('alice', 'was'), ('was', 'beginning'), ('beginning', 'to')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "alicebigrams = list(nltk.bigrams(alicewords))\n",
    "print(alicewords[:21])\n",
    "print(alicebigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "59fc34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'the', 'king', 'james', 'bible', ']', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', ':', 'called']\n",
      "[('[', 'the'), ('the', 'king'), ('king', 'james'), ('james', 'bible'), ('bible', ']'), (']', 'the'), ('the', 'old'), ('old', 'testament'), ('testament', 'of'), ('of', 'the'), ('the', 'king'), ('king', 'james'), ('james', 'bible'), ('bible', 'the'), ('the', 'first'), ('first', 'book'), ('book', 'of'), ('of', 'moses'), ('moses', ':'), (':', 'called')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "biblebigrams = list(nltk.bigrams(biblewords))\n",
    "print(biblewords[:21])\n",
    "print(biblebigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "255f79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1ab106b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "((',', 'and'), 0.013733803069206425)\n",
      "((',', \"'\"), 0.012808264166716427)\n",
      "((\"'\", 'said'), 0.009852510897474175)\n",
      "(('!', \"'\"), 0.008449274496924822)\n",
      "(('.', \"'\"), 0.00782229653072192)\n",
      "(('said', 'the'), 0.006180211381142891)\n",
      "((\"'\", 'i'), 0.005045679823251926)\n",
      "(('?', \"'\"), 0.00468740669970741)\n",
      "(('of', 'the'), 0.0038215799844748314)\n",
      "(('said', 'alice'), 0.003433450767301606)\n",
      "((\"'\", 'the'), 0.003224458111900639)\n",
      "(('in', 'a'), 0.0028960410819848332)\n",
      "((',', 'i'), 0.002418343583925479)\n",
      "(('and', 'the'), 0.00235863139666806)\n",
      "(('alice', ','), 0.0023287753030393505)\n",
      "(('in', 'the'), 0.0023287753030393505)\n",
      "(('it', 'was'), 0.0021794948348958024)\n",
      "(('the', 'queen'), 0.0020600704603809636)\n",
      "(('to', 'the'), 0.0020600704603809636)\n",
      "((',', 'but'), 0.0018510778049799965)\n",
      "((',', 'as'), 0.0018212217113512867)\n",
      "(('as', 'she'), 0.0018212217113512867)\n",
      "(('the', 'king'), 0.0018212217113512867)\n",
      "((\"'\", 'she'), 0.0017913656177225771)\n",
      "(('at', 'the'), 0.0017913656177225771)\n",
      "(('she', 'had'), 0.0017913656177225771)\n",
      "(('a', 'little'), 0.0017615095240938676)\n",
      "(('it', ','), 0.001731653430465158)\n",
      "(('*', '*'), 0.0017017973368364484)\n",
      "((\"'\", 'alice'), 0.0016719412432077386)\n",
      "(('i', \"'m\"), 0.0016719412432077386)\n",
      "(('she', 'was'), 0.0016719412432077386)\n",
      "(('mock', 'turtle'), 0.001642085149579029)\n",
      "((',', 'you'), 0.0016122290559503194)\n",
      "((';', 'and'), 0.0016122290559503194)\n",
      "(('alice', '.'), 0.0016122290559503194)\n",
      "((',', 'she'), 0.0015823729623216098)\n",
      "(('and', 'she'), 0.0015823729623216098)\n",
      "(('the', 'mock'), 0.0015823729623216098)\n",
      "(('--', \"'\"), 0.0015525168686929003)\n",
      "(('do', \"n't\"), 0.0015525168686929003)\n",
      "(('the', 'gryphon'), 0.0015525168686929003)\n",
      "(('the', 'hatter'), 0.0015525168686929003)\n",
      "(('to', 'be'), 0.0015226607750641907)\n",
      "((\"'\", \"'\"), 0.0014928046814354809)\n",
      "(('.', 'the'), 0.0014928046814354809)\n",
      "((',', 'that'), 0.0014629485878067713)\n",
      "(('went', 'on'), 0.0014330924941780617)\n",
      "(('.', 'alice'), 0.0013733803069206425)\n",
      "(('to', 'herself'), 0.001343524213291933)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder_alice = BigramCollocationFinder.from_words(alicewords)\n",
    "scored_alice = finder_alice.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "# scored is a list of bigram pairs with their score\n",
    "print(type(scored_alice))\n",
    "\n",
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored_alice[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f779ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "((',', 'and'), 0.026345251221995495)\n",
      "(('of', 'the'), 0.01218932586405749)\n",
      "(('the', 'lord'), 0.007410129994127662)\n",
      "(('and', 'the'), 0.006616941906101739)\n",
      "(('in', 'the'), 0.005312564690772825)\n",
      "((';', 'and'), 0.0033966616392694642)\n",
      "((':', 'and'), 0.0031991567491751268)\n",
      "((',', 'that'), 0.0031590220656265446)\n",
      "(('and', 'he'), 0.002946730713172203)\n",
      "((',', 'the'), 0.0026013611994778266)\n",
      "(('shall', 'be'), 0.0025992488477121116)\n",
      "(('to', 'the'), 0.002272890499909169)\n",
      "(('all', 'the'), 0.002258104037549165)\n",
      "(('and', 'they'), 0.0022031828916405792)\n",
      "(('him', ','), 0.0021514302733805653)\n",
      "(('unto', 'the'), 0.0021461493939662784)\n",
      "(('i', 'will'), 0.0020225768156719604)\n",
      "((',', 'which'), 0.0018937233579633549)\n",
      "(('lord', ','), 0.0018050045838033317)\n",
      "(('of', 'israel'), 0.0017902181214433277)\n",
      "(('said', ','), 0.0017743754832004663)\n",
      "(('for', 'the'), 0.001765926076137607)\n",
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "((':', 'for'), 0.0017236790408233103)\n",
      "(('the', 'king'), 0.001713117281994736)\n",
      "((',', 'i'), 0.001700443171400447)\n",
      "(('them', ','), 0.0016983308196347321)\n",
      "(('son', 'of'), 0.0016909375884547303)\n",
      "(('out', 'of'), 0.0015863761760518456)\n",
      "(('the', 'son'), 0.0015842638242861307)\n",
      "(('the', 'children'), 0.0014997697536575372)\n",
      "(('children', 'of'), 0.0014680844771718146)\n",
      "(('saying', ','), 0.0014057701000832266)\n",
      "((',', 'saying'), 0.0013445118988774964)\n",
      "(('the', 'land'), 0.00133078161240035)\n",
      "(('and', 'i'), 0.0013255007329860628)\n",
      "(('thou', 'shalt'), 0.0013202198535717756)\n",
      "(('the', 'people'), 0.0012906469288517677)\n",
      "(('thee', ','), 0.0012800851700231937)\n",
      "(('me', ','), 0.0012631863558974748)\n",
      "(('the', 'house'), 0.0012378381347088968)\n",
      "(('from', 'the'), 0.0012219954964660354)\n",
      "((',', 'he'), 0.0012167146170517485)\n",
      "((',', 'to'), 0.0012019281546917446)\n",
      "(('unto', 'him'), 0.0011913663958631703)\n",
      "(('behold', ','), 0.0011850293405660257)\n",
      "(('of', 'his'), 0.0011723552299717367)\n",
      "(('i', 'have'), 0.0011206026117117232)\n",
      "(('and', 'all'), 0.001107928501117434)\n",
      "(('and', 'his'), 0.0011068723252345767)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder_bible = BigramCollocationFinder.from_words(biblewords)\n",
    "scored_bible = finder_bible.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "# scored is a list of bigram pairs with their score\n",
    "print(type(scored_bible))\n",
    "\n",
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored_bible[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6c52b",
   "metadata": {},
   "source": [
    "# Remove non-alphabetical characters and list top 50 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "801066bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ffab9f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('said', 'the'), 0.006180211381142891)\n",
      "(('of', 'the'), 0.0038215799844748314)\n",
      "(('said', 'alice'), 0.003433450767301606)\n",
      "(('in', 'a'), 0.0028960410819848332)\n",
      "(('and', 'the'), 0.00235863139666806)\n",
      "(('in', 'the'), 0.0023287753030393505)\n",
      "(('it', 'was'), 0.0021794948348958024)\n",
      "(('the', 'queen'), 0.0020600704603809636)\n",
      "(('to', 'the'), 0.0020600704603809636)\n",
      "(('as', 'she'), 0.0018212217113512867)\n",
      "(('the', 'king'), 0.0018212217113512867)\n",
      "(('at', 'the'), 0.0017913656177225771)\n",
      "(('she', 'had'), 0.0017913656177225771)\n",
      "(('a', 'little'), 0.0017615095240938676)\n",
      "(('i', \"'m\"), 0.0016719412432077386)\n",
      "(('she', 'was'), 0.0016719412432077386)\n",
      "(('mock', 'turtle'), 0.001642085149579029)\n",
      "(('and', 'she'), 0.0015823729623216098)\n",
      "(('the', 'mock'), 0.0015823729623216098)\n",
      "(('do', \"n't\"), 0.0015525168686929003)\n",
      "(('the', 'gryphon'), 0.0015525168686929003)\n",
      "(('the', 'hatter'), 0.0015525168686929003)\n",
      "(('to', 'be'), 0.0015226607750641907)\n",
      "(('went', 'on'), 0.0014330924941780617)\n",
      "(('to', 'herself'), 0.001343524213291933)\n",
      "(('you', 'know'), 0.0012838120260345136)\n",
      "(('the', 'duchess'), 0.0011942437451483848)\n",
      "(('said', 'to'), 0.0011643876515196752)\n",
      "(('out', 'of'), 0.0011046754642622559)\n",
      "(('i', 'do'), 0.0010748193706335463)\n",
      "(('there', 'was'), 0.0010449632770048367)\n",
      "(('on', 'the'), 0.0010151071833761271)\n",
      "(('she', 'said'), 0.0010151071833761271)\n",
      "(('the', 'dormouse'), 0.0010151071833761271)\n",
      "(('she', 'could'), 0.0009852510897474175)\n",
      "(('with', 'the'), 0.0009852510897474175)\n",
      "(('i', \"'ve\"), 0.0009553949961187078)\n",
      "(('it', \"'s\"), 0.0009553949961187078)\n",
      "(('that', 'she'), 0.0009553949961187078)\n",
      "(('and', 'then'), 0.0009255389024899983)\n",
      "(('march', 'hare'), 0.0009255389024899983)\n",
      "(('was', 'a'), 0.0009255389024899983)\n",
      "(('the', 'other'), 0.0008956828088612886)\n",
      "(('she', 'went'), 0.000865826715232579)\n",
      "(('so', 'she'), 0.000865826715232579)\n",
      "(('the', 'march'), 0.000865826715232579)\n",
      "(('did', 'not'), 0.0008359706216038693)\n",
      "(('the', 'mouse'), 0.0008359706216038693)\n",
      "(('to', 'her'), 0.0008359706216038693)\n",
      "(('i', \"'ll\"), 0.0008061145279751597)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the bigram finder\n",
    "finder_alice.apply_word_filter(alpha_filter)\n",
    "scored_alice = finder_alice.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored_alice[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a307d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.01218932586405749)\n",
      "(('the', 'lord'), 0.007410129994127662)\n",
      "(('and', 'the'), 0.006616941906101739)\n",
      "(('in', 'the'), 0.005312564690772825)\n",
      "(('and', 'he'), 0.002946730713172203)\n",
      "(('shall', 'be'), 0.0025992488477121116)\n",
      "(('to', 'the'), 0.002272890499909169)\n",
      "(('all', 'the'), 0.002258104037549165)\n",
      "(('and', 'they'), 0.0022031828916405792)\n",
      "(('unto', 'the'), 0.0021461493939662784)\n",
      "(('i', 'will'), 0.0020225768156719604)\n",
      "(('of', 'israel'), 0.0017902181214433277)\n",
      "(('for', 'the'), 0.001765926076137607)\n",
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "(('the', 'king'), 0.001713117281994736)\n",
      "(('son', 'of'), 0.0016909375884547303)\n",
      "(('out', 'of'), 0.0015863761760518456)\n",
      "(('the', 'son'), 0.0015842638242861307)\n",
      "(('the', 'children'), 0.0014997697536575372)\n",
      "(('children', 'of'), 0.0014680844771718146)\n",
      "(('the', 'land'), 0.00133078161240035)\n",
      "(('and', 'i'), 0.0013255007329860628)\n",
      "(('thou', 'shalt'), 0.0013202198535717756)\n",
      "(('the', 'people'), 0.0012906469288517677)\n",
      "(('the', 'house'), 0.0012378381347088968)\n",
      "(('from', 'the'), 0.0012219954964660354)\n",
      "(('unto', 'him'), 0.0011913663958631703)\n",
      "(('of', 'his'), 0.0011723552299717367)\n",
      "(('i', 'have'), 0.0011206026117117232)\n",
      "(('and', 'all'), 0.001107928501117434)\n",
      "(('and', 'his'), 0.0011068723252345767)\n",
      "(('into', 'the'), 0.0011037037975860043)\n",
      "(('of', 'god'), 0.001042445596380274)\n",
      "(('unto', 'them'), 0.001022378254605983)\n",
      "(('they', 'shall'), 0.0010202659028402683)\n",
      "(('by', 'the'), 0.0010128726716602662)\n",
      "(('with', 'the'), 0.0010128726716602662)\n",
      "(('house', 'of'), 0.001007591792245979)\n",
      "(('upon', 'the'), 0.0010001985610659772)\n",
      "(('and', 'it'), 0.0009991423851831197)\n",
      "(('and', 'said'), 0.0009854120987059733)\n",
      "(('he', 'shall'), 0.0009642885810488249)\n",
      "(('and', 'when'), 0.0009621762292831101)\n",
      "(('that', 'he'), 0.0009484459428059636)\n",
      "(('saith', 'the'), 0.0009410527116259617)\n",
      "(('king', 'of'), 0.0009304909527973874)\n",
      "(('on', 'the'), 0.00092943477691453)\n",
      "(('and', 'to'), 0.0009030303798430946)\n",
      "(('the', 'earth'), 0.00089669332454595)\n",
      "(('came', 'to'), 0.0008512777615830809)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the bigram finder\n",
    "finder_bible.apply_word_filter(alpha_filter)\n",
    "scored_bible = finder_bible.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored_bible[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a152a",
   "metadata": {},
   "source": [
    "# Remove stopwords and list top 50 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c34d8409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('said', 'alice'), 0.003433450767301606)\n",
      "(('mock', 'turtle'), 0.001642085149579029)\n",
      "(('march', 'hare'), 0.0009255389024899983)\n",
      "(('thought', 'alice'), 0.0007762584343464501)\n",
      "(('white', 'rabbit'), 0.0006568340598316116)\n",
      "(('alice', 'thought'), 0.00035827312354451543)\n",
      "((\"'of\", 'course'), 0.0003284170299158058)\n",
      "(('alice', 'said'), 0.0003284170299158058)\n",
      "(('poor', 'alice'), 0.0003284170299158058)\n",
      "(('alice', 'replied'), 0.00026870484265838657)\n",
      "(('alice', 'looked'), 0.00023884874902967696)\n",
      "(('king', 'said'), 0.00023884874902967696)\n",
      "(('little', 'thing'), 0.00023884874902967696)\n",
      "(('poor', 'little'), 0.00023884874902967696)\n",
      "(('alice', 'began'), 0.00020899265540096732)\n",
      "(('cried', 'alice'), 0.00020899265540096732)\n",
      "(('good', 'deal'), 0.00020899265540096732)\n",
      "(('oh', 'dear'), 0.00020899265540096732)\n",
      "(('beautiful', 'soup'), 0.00017913656177225771)\n",
      "(('golden', 'key'), 0.00017913656177225771)\n",
      "(('great', 'hurry'), 0.00017913656177225771)\n",
      "(('little', 'door'), 0.00017913656177225771)\n",
      "(('said', 'nothing'), 0.00017913656177225771)\n",
      "(('three', 'gardeners'), 0.00017913656177225771)\n",
      "(('alice', 'felt'), 0.0001492804681435481)\n",
      "(('alice', 'went'), 0.0001492804681435481)\n",
      "(('another', 'moment'), 0.0001492804681435481)\n",
      "(('came', 'upon'), 0.0001492804681435481)\n",
      "(('cheshire', 'cat'), 0.0001492804681435481)\n",
      "(('feet', 'high'), 0.0001492804681435481)\n",
      "(('kid', 'gloves'), 0.0001492804681435481)\n",
      "(('little', 'golden'), 0.0001492804681435481)\n",
      "(('next', 'witness'), 0.0001492804681435481)\n",
      "(('offended', 'tone'), 0.0001492804681435481)\n",
      "(('play', 'croquet'), 0.0001492804681435481)\n",
      "(('right', 'size'), 0.0001492804681435481)\n",
      "(('trembling', 'voice'), 0.0001492804681435481)\n",
      "(('white', 'kid'), 0.0001492804681435481)\n",
      "(('alice', 'hastily'), 0.00011942437451483848)\n",
      "(('alice', 'ventured'), 0.00011942437451483848)\n",
      "(('come', 'back'), 0.00011942437451483848)\n",
      "(('father', 'william'), 0.00011942437451483848)\n",
      "(('hare', 'said'), 0.00011942437451483848)\n",
      "(('inches', 'high'), 0.00011942437451483848)\n",
      "(('lobster', 'quadrille'), 0.00011942437451483848)\n",
      "(('low', 'voice'), 0.00011942437451483848)\n",
      "(('never', 'heard'), 0.00011942437451483848)\n",
      "(('old', 'fellow'), 0.00011942437451483848)\n",
      "(('one', 'finger'), 0.00011942437451483848)\n",
      "(('ootiful', 'soo'), 0.00011942437451483848)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder_alice.apply_word_filter(lambda w: w in stopwords)\n",
    "scored_alice = finder_alice.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored_alice[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8f83cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('said', 'unto'), 0.0017363531514175993)\n",
      "(('thou', 'shalt'), 0.0013202198535717756)\n",
      "(('thou', 'hast'), 0.000811143078034499)\n",
      "(('ye', 'shall'), 0.0007995251433230673)\n",
      "(('lord', 'god'), 0.0005756158561572942)\n",
      "(('unto', 'thee'), 0.0005291441173115676)\n",
      "(('thus', 'saith'), 0.0004689420919886947)\n",
      "(('say', 'unto'), 0.00042035800137725336)\n",
      "(('shall', 'come'), 0.00041824564961153853)\n",
      "(('thy', 'god'), 0.0003770547901800991)\n",
      "(('thou', 'art'), 0.0003358639307486597)\n",
      "(('every', 'one'), 0.0003326954031000875)\n",
      "(('lord', 'thy'), 0.00032318982015437067)\n",
      "(('every', 'man'), 0.0003094595336772242)\n",
      "(('lord', 'hath'), 0.0003041786542629371)\n",
      "(('spake', 'unto'), 0.00028622366425436093)\n",
      "(('shalt', 'thou'), 0.00027249337777721447)\n",
      "(('lord', 'said'), 0.00023341487011148992)\n",
      "(('let', 'us'), 0.0002270778148143454)\n",
      "(('unto', 'moses'), 0.0002165160559857712)\n",
      "(('jesus', 'christ'), 0.00020912282480576926)\n",
      "(('burnt', 'offering'), 0.00019433636244576538)\n",
      "(('lord', 'shall'), 0.00019222401068005052)\n",
      "(('came', 'unto'), 0.0001911678347971931)\n",
      "(('saith', 'unto'), 0.0001911678347971931)\n",
      "(('god', 'hath'), 0.000185886955382906)\n",
      "(('thy', 'servant'), 0.00018483077950004858)\n",
      "(('pray', 'thee'), 0.00018166225185147633)\n",
      "(('right', 'hand'), 0.00017638137243718922)\n",
      "(('shall', 'ye'), 0.0001742690206714744)\n",
      "(('neither', 'shall'), 0.0001711004930229021)\n",
      "(('hast', 'thou'), 0.00016793196537432986)\n",
      "(('even', 'unto'), 0.0001594825583114705)\n",
      "(('priest', 'shall'), 0.00015631403066289823)\n",
      "(('thine', 'hand'), 0.0001552578547800408)\n",
      "(('lord', 'spake'), 0.00015208932713146856)\n",
      "(('come', 'unto'), 0.00014575227183432404)\n",
      "(('years', 'old'), 0.00014575227183432404)\n",
      "(('shall', 'go'), 0.00014363992006860918)\n",
      "(('unto', 'us'), 0.0001394152165371795)\n",
      "(('thy', 'father'), 0.00013730286477146465)\n",
      "(('unto', 'thy'), 0.00013730286477146465)\n",
      "(('thy', 'name'), 0.00013624668888860723)\n",
      "(('thy', 'people'), 0.00013624668888860723)\n",
      "(('speak', 'unto'), 0.00013307816124003498)\n",
      "(('shall', 'eat'), 0.0001299096335914627)\n",
      "(('meat', 'offering'), 0.0001288534577086053)\n",
      "(('wilt', 'thou'), 0.00012674110594289046)\n",
      "(('lord', 'came'), 0.00012568493006003304)\n",
      "(('lord', 'jesus'), 0.00012462875417717563)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder_bible.apply_word_filter(lambda w: w in stopwords)\n",
    "scored_bible = finder_bible.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored_bible[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab880a42",
   "metadata": {},
   "source": [
    "# List the top 50 bigrams by their Mutual Information scores (using min frequency 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "496ecb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"'any\", 'shrimp'), 15.03161505883576)\n",
      "((\"'cheshire\", 'puss'), 15.03161505883576)\n",
      "((\"'orange\", 'marmalade'), 15.03161505883576)\n",
      "((\"'ou\", 'est'), 15.03161505883576)\n",
      "((\"'rule\", 'forty-two'), 15.03161505883576)\n",
      "((\"'seven\", 'jogged'), 15.03161505883576)\n",
      "((\"'than\", 'waste'), 15.03161505883576)\n",
      "((\"'with\", 'extras'), 15.03161505883576)\n",
      "(('abide', 'figures'), 15.03161505883576)\n",
      "(('barking', 'hoarsely'), 15.03161505883576)\n",
      "(('bathing', 'machines'), 15.03161505883576)\n",
      "(('bright-eyed', 'terrier'), 15.03161505883576)\n",
      "(('buttered', 'toast'), 15.03161505883576)\n",
      "(('canvas', 'bag'), 15.03161505883576)\n",
      "(('carroll', '1865'), 15.03161505883576)\n",
      "(('crocodile', 'improve'), 15.03161505883576)\n",
      "(('daresay', \"it's\"), 15.03161505883576)\n",
      "(('deepest', 'contempt'), 15.03161505883576)\n",
      "(('draggled', 'feathers'), 15.03161505883576)\n",
      "(('edgar', 'atheling'), 15.03161505883576)\n",
      "(('energetic', 'remedies'), 15.03161505883576)\n",
      "(('exact', 'shape'), 15.03161505883576)\n",
      "(('fair', 'warning'), 15.03161505883576)\n",
      "(('feather', 'flock'), 15.03161505883576)\n",
      "(('graceful', 'zigzag'), 15.03161505883576)\n",
      "(('hundred', 'pounds'), 15.03161505883576)\n",
      "(('immediate', 'adoption'), 15.03161505883576)\n",
      "(('immense', 'length'), 15.03161505883576)\n",
      "(('labelled', \"'orange\"), 15.03161505883576)\n",
      "(('latin', 'grammar'), 15.03161505883576)\n",
      "(('lewis', 'carroll'), 15.03161505883576)\n",
      "(('lodging', 'houses'), 15.03161505883576)\n",
      "(('meeting', 'adjourn'), 15.03161505883576)\n",
      "(('muscular', 'strength'), 15.03161505883576)\n",
      "(('never-ending', 'meal'), 15.03161505883576)\n",
      "(('occasional', 'exclamation'), 15.03161505883576)\n",
      "(('positively', 'refused'), 15.03161505883576)\n",
      "(('prosecute', 'you.'), 15.03161505883576)\n",
      "(('reasonable', 'pace'), 15.03161505883576)\n",
      "(('red-hot', 'poker'), 15.03161505883576)\n",
      "(('riper', 'years'), 15.03161505883576)\n",
      "(('roast', 'turkey'), 15.03161505883576)\n",
      "(('saucepan', 'flew'), 15.03161505883576)\n",
      "(('shedding', 'gallons'), 15.03161505883576)\n",
      "(('sneezed', 'occasionally'), 15.03161505883576)\n",
      "(('splendidly', 'dressed'), 15.03161505883576)\n",
      "(('thank', 'ye'), 15.03161505883576)\n",
      "(('tide', 'rises'), 15.03161505883576)\n",
      "(('tinkling', 'sheep-bells'), 15.03161505883576)\n",
      "(('tittered', 'audibly'), 15.03161505883576)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "pmi_alice = BigramCollocationFinder.from_words(alicewords)\n",
    "scored_alice = pmi_alice.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored_alice[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "510b55f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('anathema', 'maranatha'), 19.852718465501717)\n",
      "(('appii', 'forum'), 19.852718465501717)\n",
      "(('ashteroth', 'karnaim'), 19.852718465501717)\n",
      "(('barbed', 'irons'), 19.852718465501717)\n",
      "(('changeable', 'suits'), 19.852718465501717)\n",
      "(('dromedary', 'traversing'), 19.852718465501717)\n",
      "(('equally', 'distant'), 19.852718465501717)\n",
      "(('eubulus', 'greeteth'), 19.852718465501717)\n",
      "(('fared', 'sumptuously'), 19.852718465501717)\n",
      "(('grandmother', 'lois'), 19.852718465501717)\n",
      "((\"herod's\", 'jurisdiction'), 19.852718465501717)\n",
      "(('infallible', 'proofs'), 19.852718465501717)\n",
      "(('je', 'hoshaphat'), 19.852718465501717)\n",
      "(('monthly', 'prognosticators'), 19.852718465501717)\n",
      "(('narrowed', 'rests'), 19.852718465501717)\n",
      "(('sergius', 'paulus'), 19.852718465501717)\n",
      "(('sticketh', 'closer'), 19.852718465501717)\n",
      "(('talitha', 'cumi'), 19.852718465501717)\n",
      "(('tottering', 'fence'), 19.852718465501717)\n",
      "(('unequally', 'yoked'), 19.852718465501717)\n",
      "(('warreth', 'entangleth'), 19.852718465501717)\n",
      "(('119:9', 'wherewithal'), 18.852718465501717)\n",
      "(('15:52', 'arab'), 18.852718465501717)\n",
      "(('15:58', 'halhul'), 18.852718465501717)\n",
      "(('15:60', 'kirjathbaal'), 18.852718465501717)\n",
      "(('57:5', 'enflaming'), 18.852718465501717)\n",
      "(('83:7', 'gebal'), 18.852718465501717)\n",
      "(('83:8', 'assur'), 18.852718465501717)\n",
      "(('bloomed', 'blossoms'), 18.852718465501717)\n",
      "(('dissolve', 'doubts'), 18.852718465501717)\n",
      "(('doubtful', 'disputations'), 18.852718465501717)\n",
      "(('exile', 'hasteneth'), 18.852718465501717)\n",
      "(('harpers', 'harping'), 18.852718465501717)\n",
      "(('heinous', 'crime'), 18.852718465501717)\n",
      "(('homeborn', 'slave'), 18.852718465501717)\n",
      "(('inhabiteth', 'eternity'), 18.852718465501717)\n",
      "(('lama', 'sabachthani'), 18.852718465501717)\n",
      "(('prosperously', 'effected'), 18.852718465501717)\n",
      "(('shameful', 'spewing'), 18.852718465501717)\n",
      "(('speedy', 'riddance'), 18.852718465501717)\n",
      "(('well-beloved', 'epaenetus'), 18.852718465501717)\n",
      "(('48:41', 'kerioth'), 18.267755964780562)\n",
      "(('68:34', 'ascribe'), 18.267755964780562)\n",
      "(('bible', ']'), 18.267755964780562)\n",
      "(('chooseth', 'strangling'), 18.267755964780562)\n",
      "(('confidently', 'affirmed'), 18.267755964780562)\n",
      "(('damnable', 'heresies'), 18.267755964780562)\n",
      "(('fallow', 'deer'), 18.267755964780562)\n",
      "(('imperious', 'whorish'), 18.267755964780562)\n",
      "(('impose', 'toll'), 18.267755964780562)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "pmi_bible = BigramCollocationFinder.from_words(biblewords)\n",
    "scored_bible = pmi_bible.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored_bible[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa790c",
   "metadata": {},
   "source": [
    "# Add frequency filter to PMI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "18061571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('play', 'croquet'), 11.768580653001967)\n",
      "(('golden', 'key'), 11.639297636056998)\n",
      "(('kid', 'gloves'), 11.572183440198463)\n",
      "(('few', 'minutes'), 10.987220939477307)\n",
      "((\"'of\", 'course'), 10.262227986977177)\n",
      "(('white', 'kid'), 10.124724463227242)\n",
      "(('beautiful', 'soup'), 9.987220939477307)\n",
      "(('three', 'gardeners'), 9.972721369782192)\n",
      "(('march', 'hare'), 9.94415221758542)\n",
      "(('good', 'deal'), 9.669044979451051)\n",
      "(('any', 'rate'), 9.613762543949864)\n",
      "(('cheshire', 'cat'), 9.598655651559655)\n",
      "(('trembling', 'voice'), 9.183618152280811)\n",
      "(('their', 'slates'), 9.166544638921868)\n",
      "((\"'d\", 'better'), 9.165366447724587)\n",
      "(('mock', 'turtle'), 9.147638855175243)\n",
      "(('next', 'witness'), 9.124724463227242)\n",
      "(('feet', 'high'), 9.105615640279538)\n",
      "(('*', '*'), 9.050723881783464)\n",
      "(('white', 'rabbit'), 9.029567230186903)\n",
      "(('your', 'majesty'), 8.999193581143384)\n",
      "(('great', 'hurry'), 8.87174372205737)\n",
      "(('your', 'pardon'), 8.86169005739345)\n",
      "(('right', 'size'), 8.746212839973513)\n",
      "(('beg', 'your'), 8.709686963948398)\n",
      "(('offended', 'tone'), 8.709686963948398)\n",
      "(('their', 'heads'), 8.622224122698057)\n",
      "(('oh', 'dear'), 8.572183440198462)\n",
      "(('its', 'mouth'), 8.461759450504811)\n",
      "((\"'m\", 'afraid'), 8.446652558114604)\n",
      "(('other', 'side'), 8.207186623419213)\n",
      "(('minute', 'or'), 8.074513017273473)\n",
      "(('another', 'moment'), 7.93991522469895)\n",
      "((\"'ve\", 'tried'), 7.820213421417289)\n",
      "(('are', 'old'), 7.814061194435693)\n",
      "(('left', 'off'), 7.786854824470858)\n",
      "(('no', 'use'), 7.76482851814086)\n",
      "(('my', 'dear'), 7.738833309607916)\n",
      "(('same', 'thing'), 7.700698180721142)\n",
      "(('let', 'me'), 7.664044298392685)\n",
      "(('very', 'politely'), 7.6496395802784605)\n",
      "((\"'off\", 'with'), 7.547799281571505)\n",
      "(('little', 'golden'), 7.5461882316655196)\n",
      "(('please', 'your'), 7.539761962506086)\n",
      "(('more', 'than'), 7.478305759384694)\n",
      "(('sat', 'down'), 7.441651877056239)\n",
      "(('or', 'two'), 7.37285429184322)\n",
      "(('ca', \"n't\"), 7.359189716864265)\n",
      "(('wo', \"n't\"), 7.359189716864265)\n",
      "(('came', 'upon'), 7.331175340694669)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "pmi_alice.apply_freq_filter(5)\n",
    "scored_alice = pmi_alice.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored_alice[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c62f1974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('untempered', 'morter'), 16.39328684686442)\n",
      "(('cock', 'crew'), 16.26775596478056)\n",
      "(('gray', 'hairs'), 15.945827869893197)\n",
      "(('cock', 'crow'), 15.782329137610319)\n",
      "(('filthy', 'lucre'), 15.502221218417583)\n",
      "(('skins', 'dyed'), 14.782329137610319)\n",
      "(('ill', 'favoured'), 14.72343544855675)\n",
      "(('judas', 'iscariot'), 14.518817728948278)\n",
      "(('curious', 'girdle'), 14.28286285717077)\n",
      "(('brook', 'kidron'), 14.277809629444484)\n",
      "(('measuring', 'reed'), 14.156247649563568)\n",
      "(('divers', 'colours'), 14.058302599151611)\n",
      "(('mary', 'magdalene'), 13.972300081254389)\n",
      "(('wreathen', 'chains'), 13.643265099872766)\n",
      "(('dyed', 'red'), 13.639371183768276)\n",
      "(('fiery', 'furnace'), 13.623899775005835)\n",
      "(('committeth', 'adultery'), 13.604790952058131)\n",
      "(('earthen', 'vessel'), 13.592190915278495)\n",
      "(('golden', 'spoon'), 13.545289940309468)\n",
      "(('bright', 'spot'), 13.520806282041733)\n",
      "(('tenth', 'deals'), 13.512868462617092)\n",
      "(('bottomless', 'pit'), 13.393286846864417)\n",
      "(('familiar', 'spirits'), 13.329156509444704)\n",
      "(('solemn', 'feasts'), 13.316665565261506)\n",
      "(('walketh', 'uprightly'), 13.232132055049838)\n",
      "(('linen', 'breeches'), 13.152278747360624)\n",
      "(('twined', 'linen'), 13.152278747360624)\n",
      "(('straitly', 'charged'), 13.042789599780285)\n",
      "(('dearly', 'beloved'), 13.032539503086529)\n",
      "(('wave', 'breast'), 13.004721558946766)\n",
      "(('flour', 'mingled'), 12.968265259012952)\n",
      "(('fine', 'twined'), 12.96215017519513)\n",
      "(('deal', 'kindly'), 12.945827869893197)\n",
      "(('sweet', 'savour'), 12.769208215876876)\n",
      "(('dealt', 'treacherously'), 12.666191496722274)\n",
      "(('burning', 'fiery'), 12.623899775005835)\n",
      "(('new', 'moons'), 12.614313726176636)\n",
      "(('parched', 'corn'), 12.595330622809064)\n",
      "(('green', 'herb'), 12.56916704232741)\n",
      "(('tender', 'mercies'), 12.567316246639468)\n",
      "(('solemn', 'assembly'), 12.549952627701249)\n",
      "(('shittim', 'wood'), 12.478322950720216)\n",
      "(('unleavened', 'cakes'), 12.448049939606419)\n",
      "(('due', 'season'), 12.4130953279446)\n",
      "(('must', 'needs'), 12.393286846864417)\n",
      "(('commit', 'adultery'), 12.389434521368813)\n",
      "(('fine', 'flour'), 12.344483509401268)\n",
      "(('summer', 'fruits'), 12.290476041280643)\n",
      "(('sing', 'praises'), 12.269844708508513)\n",
      "(('nether', 'parts'), 12.26775596478056)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "pmi_bible.apply_freq_filter(5)\n",
    "scored_bible = pmi_bible.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored_bible[:50]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6961fb",
   "metadata": {},
   "source": [
    "# Comparison of writing styles between the two texts\n",
    "Hypothesis: one aspect of the writing styles of Alice in Wonderland and the KJV Bible is words ending in 'eth', 'est', 'ath', and 'eth'. Alice in Wonderland, being a more contemporary piece of literature, will contain more common words ending in these suffixes such as \"best\", \"smallest\", or \"last\", while the KJV Bible will contain more archaic terms such as \"ruleth\", \"hast\", and \"lovest\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "19936d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w+(?:ast|eth|ath|est)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "20b5775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last', 'breath', 'best', 'twentieth', 'coast', 'least', 'conquest', 'driest', 'death', 'lest', 'nest', 'honest', 'slightest', 'highest', 'roast', 'stupidest', 'rest', 'toast', 'largest', 'deepest', 'fast', 'queerest', 'oldest', 'loveliest', 'interest', 'teeth', 'past', 'beast', 'smallest', 'underneath'}\n"
     ]
    }
   ],
   "source": [
    "matches = re.findall(pattern, ' '.join(alicewords))\n",
    "results_alice = []\n",
    "\n",
    "for match in matches:\n",
    "    results_alice.append(match)\n",
    "print(set(results_alice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e781dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'harosheth', 'afflictest', 'withholdeth', 'shaketh', 'counteth', 'dasheth', 'jerubbesheth', 'mayest', 'reproveth', 'wanderest', 'mustereth', 'committeth', 'scarest', 'hindereth', 'twentieth', 'rejoiceth', 'holdeth', 'callest', 'weakeneth', 'shameth', 'consulteth', 'riphath', 'tikvath', 'happeneth', 'drewest', 'selleth', 'findeth', 'watereth', 'possessest', 'rescueth', 'boasteth', 'pleaseth', 'spoileth', 'tilleth', 'meetest', 'requireth', 'provideth', 'bewrayeth', 'settlest', 'satest', 'scaleth', 'repentest', 'appertaineth', 'dishonourest', 'partakest', 'lackest', 'bringeth', 'slumbereth', 'eldest', 'turneth', 'readest', 'fadeth', 'earneth', 'baptizest', 'croucheth', 'tabbath', 'searchest', 'writest', 'delayeth', 'burneth', 'rewardeth', 'saluteth', 'feareth', 'meddleth', 'prevaileth', 'upholdest', 'gathereth', 'shihorlibnath', 'striveth', 'believest', 'broughtest', 'sewest', 'restest', 'causeth', 'walketh', 'markest', 'trembleth', 'delivereth', 'grieveth', 'sufferest', 'paweth', 'chinnereth', 'refuseth', 'understandest', 'ordaineth', 'desirest', 'ruleth', 'executeth', 'drinketh', 'payeth', 'appeareth', 'prevailest', 'fretteth', 'travailest', 'ashtoreth', 'tanhumeth', 'shineth', 'approvest', 'compasseth', 'liest', 'worketh', 'confirmeth', 'buildest', 'trieth', 'revilest', 'oppresseth', 'leddest', 'feignest', 'aiath', 'taketh', 'blindeth', 'warmeth', 'coveteth', 'acknowledgeth', 'ascendeth', 'deviseth', 'purgeth', 'flieth', 'dishonest', 'readeth', 'requirest', 'smiteth', 'hast', 'request', 'exceedest', 'lowest', 'sittest', 'transgressest', 'yieldeth', 'badest', 'sticketh', 'standeth', 'brakest', 'plucketh', 'slayeth', 'owest', 'honoureth', 'overpast', 'persuadest', 'thoughtest', 'cumbereth', 'lovest', 'fastest', 'sendeth', 'sinnest', 'openeth', 'prayeth', 'constraineth', 'lightest', 'adorneth', 'defileth', 'respecteth', 'intendest', 'studieth', 'lieth', 'satisfieth', 'trusteth', 'mephibosheth', 'upholdeth', 'sheath', 'teachest', 'stablisheth', 'west', 'sleepeth', 'shouteth', 'slewest', 'detest', 'performeth', 'diggeth', 'greeteth', 'cleanseth', 'bashemath', 'panteth', 'striketh', 'abhorreth', 'chastiseth', 'mephaath', 'knoweth', 'wipeth', 'delightest', 'publisheth', 'leth', 'concerneth', 'subdueth', 'heardest', 'succeedest', 'fast', 'hearest', 'passest', 'soundeth', 'filleth', 'committest', 'becamest', 'clappeth', 'renderest', 'leadest', 'pertaineth', 'troublest', 'runneth', 'path', 'sibboleth', 'preservest', 'revengeth', 'corrupteth', 'asenath', 'forsaketh', 'hidest', 'last', 'ishbosheth', 'putteth', 'reigneth', 'staggereth', 'whirleth', 'dippeth', 'hemath', 'faileth', 'sawest', 'rebellest', 'mourneth', 'provoketh', 'halteth', 'fluttereth', 'repeateth', 'increaseth', 'establisheth', 'forgettest', 'hatcheth', 'careth', 'availeth', 'goest', 'wanteth', 'betrayest', 'coast', 'thresheth', 'sentest', 'maarath', 'purifieth', 'fellest', 'upbraideth', 'treasurest', 'girdeth', 'anath', 'goath', 'compellest', 'falleth', 'enticeth', 'plotteth', 'coverest', 'shewest', 'changest', 'boweth', 'zoheleth', 'slideth', 'beatest', 'reproacheth', 'commandest', 'forest', 'barest', 'pleadeth', 'prepareth', 'escapeth', 'wotteth', 'praiseth', 'fallest', 'draweth', 'swalloweth', 'runnest', 'testifieth', 'waterest', 'waketh', 'dealest', 'gendereth', 'stumbleth', 'marketh', 'stilleth', 'cheweth', 'winketh', 'chooseth', 'forsookest', 'rebuketh', 'coucheth', 'dureth', 'sufficeth', 'nameth', 'protest', 'increasest', 'meaneth', 'rageth', 'prophesieth', 'sweareth', 'beateth', 'needest', 'rusheth', 'alameth', 'talketh', 'feedeth', 'winneth', 'loweth', 'stoopeth', 'tellest', 'mocketh', 'disannulleth', 'threwest', 'wast', 'excellest', 'satisfiest', 'marrieth', 'accuseth', 'contendeth', 'fitteth', 'reserveth', 'cheereth', 'correcteth', 'heath', 'travaileth', 'perceivest', 'resisteth', 'forbiddeth', 'camest', 'boastest', 'spendeth', 'consumeth', 'woundeth', 'breatheth', 'biddeth', 'speakest', 'baalath', 'waiteth', 'speaketh', 'causest', 'obeyeth', 'cast', 'glorifieth', 'swimmeth', 'dreameth', 'overcometh', 'seest', 'remembereth', 'askest', 'remeth', 'dresseth', 'hammoleketh', 'inhabiteth', 'foreseeth', 'changeth', 'breast', 'hath', 'rabbath', 'deserveth', 'maintainest', 'calveth', 'sheddeth', 'getteth', 'escheweth', 'kindleth', 'scornest', 'procureth', 'obtaineth', 'defendest', 'revealeth', 'overfloweth', 'observest', 'sorroweth', 'rentest', 'describeth', 'choicest', 'decayeth', 'condemneth', 'loveth', 'stretcheth', 'travelleth', 'beholdeth', 'doubteth', 'formeth', 'voweth', 'healeth', 'withdraweth', 'blast', 'standest', 'beneath', 'devoureth', 'floweth', 'sowest', 'preventest', 'scourgeth', 'overturneth', 'sophereth', 'stedfast', 'criest', 'oughtest', 'triest', 'addeth', 'clothest', 'tillest', 'understandeth', 'straitest', 'bechorath', 'holdest', 'erreth', 'fleeth', 'hammath', 'crowneth', 'exhorteth', 'asketh', 'covereth', 'seirath', 'shutteth', 'chaseth', 'priest', 'encampeth', 'containeth', 'exalteth', 'believeth', 'fleddest', 'breaketh', 'bendeth', 'heapeth', 'slandereth', 'lighteneth', 'recompensest', 'cleaveth', 'meshullemeth', 'uttereth', 'entangleth', 'gaddest', 'withheldest', 'seeth', 'laboureth', 'tempest', 'slanderest', 'opposeth', 'excelleth', 'hazarmaveth', 'withereth', 'parteth', 'despiseth', 'modest', 'frameth', 'edifieth', 'calleth', 'lifteth', 'curseth', 'singeth', 'stealeth', 'reignest', 'sojourneth', 'buyest', 'rest', 'timnath', 'stayeth', 'gropeth', 'deckest', 'servest', 'bath', 'belongest', 'directeth', 'eightieth', 'madest', 'guest', 'tempteth', 'planteth', 'licketh', 'blotteth', 'jehoshabeath', 'fighteth', 'gnasheth', 'lettest', 'converteth', 'warreth', 'gath', 'hideth', 'helkath', 'liketh', 'knewest', 'descendeth', 'comest', 'settest', 'fewest', 'greatest', 'slippeth', 'steppeth', 'hareth', 'fortieth', 'lest', 'bringest', 'aileth', 'swarest', 'crownest', 'usest', 'profiteth', 'diblath', 'preachest', 'weavest', 'deferreth', 'soweth', 'exacteth', 'nest', 'mightiest', 'liveth', 'weepeth', 'roast', 'layest', 'commendeth', 'fearest', 'hearkeneth', 'doest', 'goodliest', 'suffereth', 'rolleth', 'coupleth', 'heth', 'enrichest', 'shimrath', 'preacheth', 'sharpeneth', 'rulest', 'tendeth', 'deliverest', 'spendest', 'loadeth', 'helpeth', 'approveth', 'perceiveth', 'vilest', 'pondereth', 'humbleth', 'overthroweth', 'earnest', 'japheth', 'stoppeth', 'washest', 'preserveth', 'seeketh', 'rendereth', 'reckoneth', 'jahath', 'hurleth', 'endeth', 'lacketh', 'riseth', 'groaneth', 'foundest', 'hardeneth', 'proclaimeth', 'spreadest', 'anointest', 'stinketh', 'foameth', 'shimeath', 'springeth', 'rejecteth', 'dabbasheth', 'biteth', 'pibeseth', 'youngest', 'willeth', 'groweth', 'bereaveth', 'keepest', 'handleth', 'answerest', 'wreath', 'inheriteth', 'justifieth', 'scattereth', 'saveth', 'dwellest', 'ahuzzath', 'sanctifieth', 'roareth', 'forgavest', 'looseth', 'choosest', 'behaveth', 'numberest', 'awakest', 'belongeth', 'returneth', 'smootheth', 'nourisheth', 'divineth', 'forgetteth', 'closest', 'blasphemest', 'troubleth', 'leaneth', 'oweth', 'sigheth', 'peleth', 'receiveth', 'tasteth', 'sayest', 'vanisheth', 'killeth', 'observeth', 'proveth', 'enlargeth', 'ministereth', 'beast', 'languisheth', 'retaineth', 'genubath', 'underneath', 'breakest', 'carest', 'elisabeth', 'tibhath', 'baptizeth', 'borroweth', 'thirsteth', 'bewaileth', 'separateth', 'contendest', 'sitteth', 'shouldest', 'sheweth', 'naarath', 'bindeth', 'presseth', 'wearieth', 'owneth', 'judgest', 'lodgeth', 'restrainest', 'wrest', 'confesseth', 'compoundeth', 'hathath', 'tahath', 'chastenest', 'maath', 'needeth', 'mispereth', 'departeth', 'blessest', 'visitest', 'backbiteth', 'feedest', 'goeth', 'turnest', 'fainteth', 'ordereth', 'reapeth', 'enviest', 'elath', 'offereth', 'straiteneth', 'basmath', 'kohath', 'loatheth', 'appeaseth', 'bloweth', 'girdest', 'zephath', 'multiplieth', 'accepteth', 'valuest', 'thinkest', 'alemeth', 'seweth', 'ploweth', 'makest', 'stillest', 'prolongeth', 'sheth', 'openest', 'eatest', 'leaveth', 'affecteth', 'delighteth', 'hateth', 'pineth', 'leaveneth', 'advantageth', 'lusteth', 'entreateth', 'desireth', 'taphath', 'rattleth', 'forbeareth', 'roasteth', 'seekest', 'forgiveth', 'buildeth', 'foldeth', 'lendeth', 'betrayeth', 'disappointeth', 'reproachest', 'listeth', 'gloriest', 'setteth', 'wasteth', 'mithredath', 'manahath', 'telleth', 'kirhareseth', 'hopeth', 'thinketh', 'couldest', 'honourest', 'snuffeth', 'basest', 'flattereth', 'redeemeth', 'pardoneth', 'opposest', 'graveth', 'hamath', 'watcheth', 'begetteth', 'strongest', 'spreadeth', 'hasteth', 'nazareth', 'death', 'wrath', 'destroyest', 'regardeth', 'witnesseth', 'frustrateth', 'stoodest', 'mightest', 'remaineth', 'writeth', 'fiftieth', 'fattest', 'zoheth', 'craveth', 'persuadeth', 'east', 'risest', 'knowest', 'favourest', 'envieth', 'zarephath', 'wouldest', 'anaharath', 'compassest', 'sleepest', 'seth', 'proceedeth', 'passeth', 'smallest', 'boast', 'repayeth', 'poorest', 'alloweth', 'tookest', 'spareth', 'appointeth', 'chargest', 'pursueth', 'walkest', 'convinceth', 'considerest', 'persecutest', 'trustest', 'endureth', 'differeth', 'possesseth', 'ramath', 'transgresseth', 'letteth', 'poureth', 'wakeneth', 'weareth', 'castest', 'layeth', 'altereth', 'flourisheth', 'condemnest', 'resteth', 'repliest', 'deceiveth', 'oath', 'devourest', 'worshippeth', 'quickeneth', 'aboundeth', 'catcheth', 'fillest', 'searcheth', 'ladeth', 'esteemeth', 'decketh', 'cuttest', 'azmaveth', 'agreeth', 'exerciseth', 'renewest', 'vomiteth', 'treadeth', 'continueth', 'ceaseth', 'favoureth', 'perisheth', 'mockest', 'savourest', 'dealeth', 'teeth', 'moveth', 'refresheth', 'savest', 'longeth', 'disguiseth', 'refraineth', 'outcast', 'benzoheth', 'chanceth', 'breath', 'shibboleth', 'baketh', 'chest', 'waxeth', 'best', 'comforteth', 'gibeath', 'lodgest', 'puttest', 'laugheth', 'casteth', 'lotheth', 'sabbath', 'abideth', 'begettest', 'scorneth', 'daberath', 'weepest', 'preparest', 'followeth', 'divideth', 'hunteth', 'createth', 'extendeth', 'leadeth', 'bozkath', 'overtaketh', 'contemneth', 'honest', 'talkest', 'seduceth', 'maketh', 'meanest', 'buyeth', 'givest', 'considereth', 'terrifiest', 'profaneth', 'serveth', 'regardest', 'wandereth', 'melteth', 'entereth', 'lingereth', 'manifest', 'sprinkleth', 'cometh', 'puffeth', 'forecast', 'pierceth', 'removeth', 'lappeth', 'mast', 'spakest', 'valiantest', 'awaketh', 'vaunteth', 'fashioneth', 'occupieth', 'blasphemeth', 'destroyeth', 'killest', 'feast', 'reapest', 'trimmest', 'intermeddleth', 'playeth', 'tarrieth', 'smelleth', 'crieth', 'hirest', 'droppeth', 'beginnest', 'executest', 'giveth', 'sacrificeth', 'rememberest', 'despisest', 'boscath', 'wentest', 'ephrath', 'goliath', 'ariseth', 'leftest', 'consisteth', 'chiefest', 'stirreth', 'challengeth', 'kirharaseth', 'bethazmaveth', 'hasteneth', 'remainest', 'useth', 'winnoweth', 'tarriest', 'limiteth', 'bridleth', 'fairest', 'blesseth', 'gatherest', 'darkeneth', 'chasteneth', 'kattath', 'dishonoureth', 'driveth', 'kenath', 'weigheth', 'avengeth', 'pochereth', 'acceptest', 'commandeth', 'visiteth', 'smotest', 'bethanath', 'smitest', 'hangeth', 'hottest', 'drieth', 'enquirest', 'rejoicest', 'sinneth', 'meeteth', 'spoilest', 'keepeth', 'discerneth', 'diddest', 'shooteth', 'glorieth', 'uncovereth', 'imputeth', 'relieveth', 'hatest', 'mahalath', 'perverteth', 'thirtieth', 'sighest', 'toucheth', 'imagineth', 'concealeth', 'vowest', 'wavereth', 'zereth', 'sellest', 'huntest', 'knocketh', 'ashvath', 'cherisheth', 'mahath', 'looketh', 'purposeth', 'highest', 'repenteth', 'teacheth', 'befalleth', 'wrongeth', 'climbeth', 'rakkath', 'becometh', 'trickleth', 'takest', 'signifieth', 'judgeth', 'pisseth', 'pitieth', 'stingeth', 'distributeth', 'carrieth', 'raiseth', 'past', 'sealest', 'stonest', 'sendest', 'faintest', 'lookest', 'denieth', 'exceedeth', 'wroughtest', 'shallecheth', 'liftest', 'stretchest', 'livest', 'strengtheneth', 'zererath', 'dieth', 'prospereth', 'dissembleth', 'loseth', 'nahath', 'holiest', 'fetcheth', 'prayest', 'ginath', 'seemeth', 'supplieth', 'thrusteth', 'thundereth', 'topheth', 'beholdest', 'least', 'restoreth', 'exaltest', 'lighteth', 'reacheth', 'dissolvest', 'withdrawest', 'gavest', 'sealeth', 'heareth', 'cursest', 'cutteth', 'answereth', 'creepeth', 'findest', 'discovereth', 'harvest', 'bearest', 'declareth', 'moreshethgath', 'diest', 'teareth', 'kirjath', 'declineth', 'inhabitest', 'inclineth', 'pacifieth', 'tebeth', 'robbeth', 'abhorrest', 'rideth', 'dwelleth', 'emboldeneth', 'beareth', 'doeth', 'quieteth', 'eateth', 'jotbath', 'approacheth', 'carriest', 'abodest', 'swimmest', 'heweth', 'finest', 'jetheth'}\n"
     ]
    }
   ],
   "source": [
    "matches = re.findall(pattern, ' '.join(biblewords))\n",
    "results_bible = []\n",
    "\n",
    "for match in matches:\n",
    "    results_bible.append(match)\n",
    "print(set(results_bible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e358ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
