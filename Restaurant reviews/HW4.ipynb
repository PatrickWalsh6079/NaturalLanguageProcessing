{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820c2f8e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76afbebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\patrick\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\patrick\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceab2466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lie</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'Mike\\'s Pizza High Point</td>\n",
       "      <td>NY Service was very slow and the quality was ...</td>\n",
       "      <td>not. Stick to pre-made dishes like stuffed pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'i really like this buffet restaurant in Marsh...</td>\n",
       "      <td>japanese</td>\n",
       "      <td>and chinese dishes. we also got a free drink ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'After I went shopping with some of my friend</td>\n",
       "      <td>we went to DODO restaurant for dinner. I foun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'Olive Oil Garden was very disappointing. I ex...</td>\n",
       "      <td>and the waitor had no manners whatsoever. Don...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'The Seven Heaven restaurant was never known f...</td>\n",
       "      <td>never more. '</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  lie sentiment                                             review  \\\n",
       "0   f         n                          'Mike\\'s Pizza High Point   \n",
       "1   f         n  'i really like this buffet restaurant in Marsh...   \n",
       "2   f         n      'After I went shopping with some of my friend   \n",
       "3   f         n  'Olive Oil Garden was very disappointing. I ex...   \n",
       "4   f         n  'The Seven Heaven restaurant was never known f...   \n",
       "\n",
       "                                          Unnamed: 3  \\\n",
       "0   NY Service was very slow and the quality was ...   \n",
       "1                                           japanese   \n",
       "2   we went to DODO restaurant for dinner. I foun...   \n",
       "3   and the waitor had no manners whatsoever. Don...   \n",
       "4                                      never more. '   \n",
       "\n",
       "                                          Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
       "0   not. Stick to pre-made dishes like stuffed pa...        NaN        NaN   \n",
       "1   and chinese dishes. we also got a free drink ...        NaN        NaN   \n",
       "2                                                NaN        NaN        NaN   \n",
       "3                                                NaN        NaN        NaN   \n",
       "4                                                NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 14 Unnamed: 15 Unnamed: 16  \\\n",
       "0        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
       "1        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
       "2        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
       "3        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
       "4        NaN        NaN        NaN  ...         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 17 Unnamed: 18 Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 23  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"C:/Users/Patrick/Syracuse_courses/IST_736/HW4/deception_data_two_labels.csv\"\n",
    "\n",
    "original_df = pd.read_csv(file)\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732ee42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lie</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'Mike\\'s Pizza High Point  NY Service was very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'i really like this buffet restaurant in Marsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'After I went shopping with some of my friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'Olive Oil Garden was very disappointing. I ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>'The Seven Heaven restaurant was never known f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lie sentiment                                             review\n",
       "0   f         n  'Mike\\'s Pizza High Point  NY Service was very...\n",
       "1   f         n  'i really like this buffet restaurant in Marsh...\n",
       "2   f         n  'After I went shopping with some of my friend ...\n",
       "3   f         n  'Olive Oil Garden was very disappointing. I ex...\n",
       "4   f         n  'The Seven Heaven restaurant was never known f..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine review columns into one column and drop remaining, empty columns\n",
    "original_df['review'] = original_df.iloc[:, 2:].apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
    "cleaned_df = original_df.drop(original_df.columns[3:], axis=1)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6f017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lie</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>Mike's Pizza High Point  NY Service was very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>i really like this buffet restaurant in Marsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>After I went shopping with some of my friend  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>Olive Oil Garden was very disappointing. I exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>The Seven Heaven restaurant was never known fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lie sentiment                                             review\n",
       "0   f         n  Mike's Pizza High Point  NY Service was very s...\n",
       "1   f         n  i really like this buffet restaurant in Marsha...\n",
       "2   f         n  After I went shopping with some of my friend  ...\n",
       "3   f         n  Olive Oil Garden was very disappointing. I exp...\n",
       "4   f         n  The Seven Heaven restaurant was never known fo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove miscellaneous characters from review column\n",
    "cleaned_df['review'] = (cleaned_df['review'].str.replace(\"f'\", '', regex=True)\n",
    "                .str.replace(\"t'\", '', regex=True)\n",
    "                .str.replace('\\\\', '', regex=True))  \n",
    "cleaned_df['review'] = cleaned_df['review'].str.rstrip(\"'\")  # remove final single quote\n",
    "cleaned_df['review'] = cleaned_df['review'].str.replace(\"'\", \"\", 1)  # remove first single quote from each row\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f06023b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mike's Pizza High Point  NY Service was very slow and the quality was low. You would think they would know at least how to make good pizza  not. Stick to pre-made dishes like stuffed pasta or a salad. You should consider dining else where.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635048b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>Mike's Pizza High Point  NY Service was very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>i really like this buffet restaurant in Marsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>After I went shopping with some of my friend  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>Olive Oil Garden was very disappointing. I exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>The Seven Heaven restaurant was never known fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL                                             review\n",
       "0     f  Mike's Pizza High Point  NY Service was very s...\n",
       "1     f  i really like this buffet restaurant in Marsha...\n",
       "2     f  After I went shopping with some of my friend  ...\n",
       "3     f  Olive Oil Garden was very disappointing. I exp...\n",
       "4     f  The Seven Heaven restaurant was never known fo..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract lie label and create separate df from cleaned df\n",
    "lie_df = cleaned_df.drop(cleaned_df.columns[1],axis=1)\n",
    "lie_df = lie_df.rename(columns={'lie':'LABEL'})\n",
    "lie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bac96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>Mike's Pizza High Point  NY Service was very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>i really like this buffet restaurant in Marsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>After I went shopping with some of my friend  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>Olive Oil Garden was very disappointing. I exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>The Seven Heaven restaurant was never known fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL                                             review\n",
       "0     n  Mike's Pizza High Point  NY Service was very s...\n",
       "1     n  i really like this buffet restaurant in Marsha...\n",
       "2     n  After I went shopping with some of my friend  ...\n",
       "3     n  Olive Oil Garden was very disappointing. I exp...\n",
       "4     n  The Seven Heaven restaurant was never known fo..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract sentiment label and create separate df from cleaned df\n",
    "sentiment_df = cleaned_df.drop(cleaned_df.columns[0],axis=1)\n",
    "sentiment_df = sentiment_df.rename(columns={'sentiment':'LABEL'})\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fae71d",
   "metadata": {},
   "source": [
    "# Tokenization/Vectorization\n",
    "This code will produce 4 dataframes: \n",
    "1. a vectorized df of the lie dataset using CountVectorizer, \n",
    "2. a vectorized df\n",
    "of the lie dataset using TfidfVectorizer, \n",
    "3. a vectorized df of the sentiment dataset using CountVectorizer, and \n",
    "4. a \n",
    "vectorized df of the sentiment dataset using TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f151b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# create CountVectorizer() object\n",
    "MyLieCV = CountVectorizer(input='content', stop_words='english')\n",
    "# create TfidfVectorizer() object\n",
    "MyLieTFIDF = TfidfVectorizer(input='content', stop_words='english')\n",
    "\n",
    "MySentCV = CountVectorizer(input='content', stop_words='english')\n",
    "MySentTFIDF = TfidfVectorizer(input='content', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72effdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LABEL  10  100  15  16  20  25  2nd  30  50  ...  write  written  wrong  \\\n",
      "0     f   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "1     f   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "2     f   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "3     f   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "4     f   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "\n",
      "   wrote  xyz  yeah  yelp  yesterday  york  yuenan  \n",
      "0      0    0     0     0          0     0       0  \n",
      "1      0    0     0     0          0     0       0  \n",
      "2      0    0     0     0          0     0       0  \n",
      "3      0    0     0     0          0     0       0  \n",
      "4      0    0     0     0          0     0       0  \n",
      "\n",
      "[5 rows x 1255 columns]\n"
     ]
    }
   ],
   "source": [
    "# create document term matrix using CV object\n",
    "dtm_lie_cv = MyLieCV.fit_transform(lie_df['review'])\n",
    "# vectorize df\n",
    "vectorized_lie_cv = pd.DataFrame(dtm_lie_cv.toarray(), columns=MyLieCV.get_feature_names_out())\n",
    "\n",
    "vectorized_lie_cv.insert(0, 'LABEL', lie_df['LABEL'])\n",
    "print(vectorized_lie_cv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e6c35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LABEL   10  100   15   16   20   25  2nd   30   50  ...  write  written  \\\n",
      "0     f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "1     f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "2     f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "3     f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "4     f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "\n",
      "   wrong  wrote  xyz  yeah  yelp  yesterday  york  yuenan  \n",
      "0    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "1    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "2    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "3    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "4    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "\n",
      "[5 rows x 1255 columns]\n"
     ]
    }
   ],
   "source": [
    "# create document term matrix using CV object\n",
    "dtm_lie_tfidf = MyLieTFIDF.fit_transform(lie_df['review'])\n",
    "# vectorize df\n",
    "vectorized_lie_tfidf = pd.DataFrame(dtm_lie_tfidf.toarray(), columns=MyLieTFIDF.get_feature_names_out())\n",
    "\n",
    "vectorized_lie_tfidf.insert(0, 'LABEL', lie_df['LABEL'])\n",
    "print(vectorized_lie_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4371d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LABEL  10  100  15  16  20  25  2nd  30  50  ...  write  written  wrong  \\\n",
      "0     n   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "1     n   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "2     n   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "3     n   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "4     n   0    0   0   0   0   0    0   0   0  ...      0        0      0   \n",
      "\n",
      "   wrote  xyz  yeah  yelp  yesterday  york  yuenan  \n",
      "0      0    0     0     0          0     0       0  \n",
      "1      0    0     0     0          0     0       0  \n",
      "2      0    0     0     0          0     0       0  \n",
      "3      0    0     0     0          0     0       0  \n",
      "4      0    0     0     0          0     0       0  \n",
      "\n",
      "[5 rows x 1255 columns]\n"
     ]
    }
   ],
   "source": [
    "dtm_sentiment_cv = MySentCV.fit_transform(sentiment_df['review'])\n",
    "vectorized_sentiment_cv = pd.DataFrame(dtm_sentiment_cv.toarray(), columns=MySentCV.get_feature_names_out())\n",
    "\n",
    "vectorized_sentiment_cv.insert(0, 'LABEL', sentiment_df['LABEL'])\n",
    "print(vectorized_sentiment_cv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c0cbfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LABEL   10  100   15   16   20   25  2nd   30   50  ...  write  written  \\\n",
      "0     n  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "1     n  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "2     n  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "3     n  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "4     n  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0      0.0   \n",
      "\n",
      "   wrong  wrote  xyz  yeah  yelp  yesterday  york  yuenan  \n",
      "0    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "1    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "2    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "3    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "4    0.0    0.0  0.0   0.0   0.0        0.0   0.0     0.0  \n",
      "\n",
      "[5 rows x 1255 columns]\n"
     ]
    }
   ],
   "source": [
    "dtm_sentiment_tfidf = MySentTFIDF.fit_transform(sentiment_df['review'])\n",
    "vectorized_sentiment_tfidf = pd.DataFrame(dtm_sentiment_tfidf.toarray(), columns=MySentTFIDF.get_feature_names_out())\n",
    "\n",
    "vectorized_sentiment_tfidf.insert(0, 'LABEL', sentiment_df['LABEL'])\n",
    "print(vectorized_sentiment_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ece188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lie DF, CV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>abc</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accord</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuenan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL  abc  abruptly  absolutely  acceptable  accord  acknowledge  actual  \\\n",
       "0     f    0         0           0           0       0            0       0   \n",
       "1     f    0         0           0           0       0            0       0   \n",
       "2     f    0         0           0           0       0            0       0   \n",
       "3     f    0         0           0           0       0            0       0   \n",
       "4     f    0         0           0           0       0            0       0   \n",
       "\n",
       "   actually  ad  ...  write  written  wrong  wrote  xyz  yeah  yelp  \\\n",
       "0         0   0  ...      0        0      0      0    0     0     0   \n",
       "1         0   0  ...      0        0      0      0    0     0     0   \n",
       "2         0   0  ...      0        0      0      0    0     0     0   \n",
       "3         0   0  ...      0        0      0      0    0     0     0   \n",
       "4         0   0  ...      0        0      0      0    0     0     0   \n",
       "\n",
       "   yesterday  york  yuenan  \n",
       "0          0     0       0  \n",
       "1          0     0       0  \n",
       "2          0     0       0  \n",
       "3          0     0       0  \n",
       "4          0     0       0  \n",
       "\n",
       "[5 rows x 1243 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove columns with digits\n",
    "def alpha_only(df):\n",
    "    columns_to_drop = [col for col in df.columns if any(char.isdigit() for char in col)]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('Lie DF, CV:')\n",
    "vectorized_lie_cv = alpha_only(vectorized_lie_cv)\n",
    "vectorized_lie_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1cf8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lie DF, TFIDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>abc</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accord</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuenan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL  abc  abruptly  absolutely  acceptable  accord  acknowledge  actual  \\\n",
       "0     f  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "1     f  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "2     f  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "3     f  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "4     f  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "\n",
       "   actually   ad  ...  write  written  wrong  wrote  xyz  yeah  yelp  \\\n",
       "0       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "1       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "2       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "3       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "4       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "   yesterday  york  yuenan  \n",
       "0        0.0   0.0     0.0  \n",
       "1        0.0   0.0     0.0  \n",
       "2        0.0   0.0     0.0  \n",
       "3        0.0   0.0     0.0  \n",
       "4        0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 1243 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Lie DF, TFIDF:')\n",
    "vectorized_lie_tfidf = alpha_only(vectorized_lie_tfidf)\n",
    "vectorized_lie_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32d71055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment DF, CV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>abc</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accord</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuenan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL  abc  abruptly  absolutely  acceptable  accord  acknowledge  actual  \\\n",
       "0     n    0         0           0           0       0            0       0   \n",
       "1     n    0         0           0           0       0            0       0   \n",
       "2     n    0         0           0           0       0            0       0   \n",
       "3     n    0         0           0           0       0            0       0   \n",
       "4     n    0         0           0           0       0            0       0   \n",
       "\n",
       "   actually  ad  ...  write  written  wrong  wrote  xyz  yeah  yelp  \\\n",
       "0         0   0  ...      0        0      0      0    0     0     0   \n",
       "1         0   0  ...      0        0      0      0    0     0     0   \n",
       "2         0   0  ...      0        0      0      0    0     0     0   \n",
       "3         0   0  ...      0        0      0      0    0     0     0   \n",
       "4         0   0  ...      0        0      0      0    0     0     0   \n",
       "\n",
       "   yesterday  york  yuenan  \n",
       "0          0     0       0  \n",
       "1          0     0       0  \n",
       "2          0     0       0  \n",
       "3          0     0       0  \n",
       "4          0     0       0  \n",
       "\n",
       "[5 rows x 1243 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sentiment DF, CV:')\n",
    "vectorized_sentiment_cv = alpha_only(vectorized_sentiment_cv)\n",
    "vectorized_sentiment_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01dd2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment DF, TFIDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>abc</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accord</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuenan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL  abc  abruptly  absolutely  acceptable  accord  acknowledge  actual  \\\n",
       "0     n  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "1     n  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "2     n  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "3     n  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "4     n  0.0       0.0         0.0         0.0     0.0          0.0     0.0   \n",
       "\n",
       "   actually   ad  ...  write  written  wrong  wrote  xyz  yeah  yelp  \\\n",
       "0       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "1       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "2       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "3       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "4       0.0  0.0  ...    0.0      0.0    0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "   yesterday  york  yuenan  \n",
       "0        0.0   0.0     0.0  \n",
       "1        0.0   0.0     0.0  \n",
       "2        0.0   0.0     0.0  \n",
       "3        0.0   0.0     0.0  \n",
       "4        0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 1243 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sentiment DF, TFIDF:')\n",
    "vectorized_sentiment_tfidf = alpha_only(vectorized_sentiment_tfidf)\n",
    "vectorized_sentiment_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727805e",
   "metadata": {},
   "source": [
    "The preceeding blocks of code created the 4 dataframes using CountVectorizer and TfidfVectorizer. Now it's time to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30731f8",
   "metadata": {},
   "source": [
    "# Train Naive Bayes model\n",
    "These code blocks split the 4 dataframes created in the prior blocks into training and testing segments with a \n",
    "70% - 30% split for training and testing. Each of the 4 training segments will be used to create 4 separate models:\n",
    "\n",
    "Model 1: Lie detection model trained on a CountVectorizer() df,\n",
    "\n",
    "Model 2: Lie detection model trained on a TfidfVectorizer() df,\n",
    "\n",
    "Model 3: Sentiment classification model trained on a CountVectorizer() df, and\n",
    "\n",
    "Model 4: Sentiment classification model trained on a TfidfVectorizer() df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5362ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TrainLieCV, TestLieCV = train_test_split(vectorized_lie_cv, test_size=0.3)  # model 1\n",
    "TrainLieTFIDF, TestLieTFIDF = train_test_split(vectorized_lie_tfidf, test_size=0.3)  # model 2\n",
    "TrainSentCV, TestSentCV = train_test_split(vectorized_sentiment_cv, test_size=0.3)  # model 3\n",
    "TrainSentTFIDF, TestSentTFIDF = train_test_split(vectorized_sentiment_tfidf, test_size=0.3)  # model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8173189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split testing labels from testing data\n",
    "TestLieCVLabels = TestLieCV['LABEL']\n",
    "TestLieTFIDFLabels = TestLieTFIDF['LABEL']\n",
    "TestSentCVLabels = TestSentCV['LABEL']\n",
    "TestSentTFIDFLabels = TestSentTFIDF['LABEL']\n",
    "\n",
    "TestLieCV = TestLieCV.drop([\"LABEL\"], axis=1)  # remove the entire column\n",
    "TestLieTFIDF = TestLieTFIDF.drop([\"LABEL\"], axis=1)\n",
    "TestSentCV = TestSentCV.drop([\"LABEL\"], axis=1)\n",
    "TestSentTFIDF = TestSentTFIDF.drop([\"LABEL\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474daebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training labels from training data\n",
    "TrainLieCVLabels = TrainLieCV['LABEL']\n",
    "TrainLieTFIDFLabels = TrainLieTFIDF['LABEL']\n",
    "TrainSentCVLabels = TrainSentCV['LABEL']\n",
    "TrainSentTFIDFLabels = TrainSentTFIDF['LABEL']\n",
    "\n",
    "TrainLieCV = TrainLieCV.drop([\"LABEL\"], axis=1)  # remove the entire column\n",
    "TrainLieTFIDF = TrainLieTFIDF.drop([\"LABEL\"], axis=1)\n",
    "TrainSentCV = TrainSentCV.drop([\"LABEL\"], axis=1)\n",
    "TrainSentTFIDF = TrainSentTFIDF.drop([\"LABEL\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8401d2",
   "metadata": {},
   "source": [
    "Create models and fit training sets to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f77fbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "MyModel1 = MultinomialNB()\n",
    "MyModel2 = MultinomialNB()\n",
    "MyModel3 = MultinomialNB()\n",
    "MyModel4 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73430447",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "203d1ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f' 'f' 'f' 't' 'f' 'f' 'f' 'f' 'f' 't' 't' 't' 'f' 'f' 'f' 'f' 'f' 'f'\n",
      " 't' 'f' 'f' 't' 't' 't' 't' 'f' 't' 'f']\n",
      "[[0.91 0.09]\n",
      " [1.   0.  ]\n",
      " [0.75 0.25]\n",
      " [0.1  0.9 ]\n",
      " [0.93 0.07]\n",
      " [0.74 0.26]\n",
      " [1.   0.  ]\n",
      " [0.82 0.18]\n",
      " [1.   0.  ]\n",
      " [0.03 0.97]\n",
      " [0.07 0.93]\n",
      " [0.3  0.7 ]\n",
      " [0.93 0.07]\n",
      " [0.94 0.06]\n",
      " [0.99 0.01]\n",
      " [0.98 0.02]\n",
      " [0.98 0.02]\n",
      " [0.95 0.05]\n",
      " [0.44 0.56]\n",
      " [0.87 0.13]\n",
      " [1.   0.  ]\n",
      " [0.24 0.76]\n",
      " [0.08 0.92]\n",
      " [0.01 0.99]\n",
      " [0.03 0.97]\n",
      " [0.56 0.44]\n",
      " [0.09 0.91]\n",
      " [0.59 0.41]]\n"
     ]
    }
   ],
   "source": [
    "LieCV = MyModel1.fit(TrainLieCV, TrainLieCVLabels)\n",
    "PredLieCV = MyModel1.predict(TestLieCV)\n",
    "print(PredLieCV)\n",
    "print(np.round(MyModel1.predict_proba(TestLieCV),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cf268",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3647726",
   "metadata": {},
   "outputs": [],
   "source": [
    "LieTFIDF = MyModel2.fit(TrainLieTFIDF, TrainLieTFIDFLabels)\n",
    "PredLieTFIDF = MyModel2.predict(TestLieTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6194b",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6a79099",
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentCV = MyModel3.fit(TrainSentCV, TrainSentCVLabels)\n",
    "PredSentimentCV = MyModel3.predict(TestSentCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b51422",
   "metadata": {},
   "source": [
    "Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "531157bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentTFIDF = MyModel4.fit(TrainSentTFIDF, TrainSentTFIDFLabels)\n",
    "PredSentimentTFIDF = MyModel4.predict(TestSentTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ccbf9",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e25dd",
   "metadata": {},
   "source": [
    "### Fake Review Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b63162e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Model 1 confusion matrix is:\n",
      "[[ 5  5]\n",
      " [13  5]]\n",
      "\n",
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35714285714285715"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cnf_matrix1 = confusion_matrix(TestLieCVLabels, PredLieCV)\n",
    "print(\"\\nThe Model 1 confusion matrix is:\")\n",
    "print(cnf_matrix1)\n",
    "\n",
    "print('\\nAccuracy:')\n",
    "accuracy_score(TestLieCVLabels, PredLieCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd88c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Model 2 confusion matrix is:\n",
      "[[5 8]\n",
      " [7 8]]\n",
      "\n",
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4642857142857143"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix2 = confusion_matrix(TestLieTFIDFLabels, PredLieTFIDF)\n",
    "print(\"\\nThe Model 2 confusion matrix is:\")\n",
    "print(cnf_matrix2)\n",
    "\n",
    "print('\\nAccuracy:')\n",
    "accuracy_score(TestLieTFIDFLabels, PredLieTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b9f61",
   "metadata": {},
   "source": [
    "### Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "925e9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Model 3 confusion matrix is:\n",
      "[[14  2]\n",
      " [ 0 12]]\n",
      "\n",
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix3 = confusion_matrix(TestSentCVLabels, PredSentimentCV)\n",
    "print(\"\\nThe Model 3 confusion matrix is:\")\n",
    "print(cnf_matrix3)\n",
    "\n",
    "print('\\nAccuracy:')\n",
    "accuracy_score(TestSentCVLabels, PredSentimentCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1639feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Model 4 confusion matrix is:\n",
      "[[13  0]\n",
      " [ 5 10]]\n",
      "\n",
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix4 = confusion_matrix(TestSentTFIDFLabels, PredSentimentTFIDF)\n",
    "print(\"\\nThe Model 4 confusion matrix is:\")\n",
    "print(cnf_matrix4)\n",
    "\n",
    "print('\\nAccuracy:')\n",
    "accuracy_score(TestSentTFIDFLabels, PredSentimentTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa7f67",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a11177",
   "metadata": {},
   "source": [
    "### Lie Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4688971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1\n",
      "Features for FALSE class:\n",
      "['regrettably' 'flavor' 'warmly' 'perplexing' 'seated' 'bean' 'meats'\n",
      " 'piano' 'ethic' 'lasagna']\n",
      "\n",
      "Features for TRUE class:\n",
      "['regrettably' 'flavor' 'perplexing' 'gently' 'offered' 'warmly' 'gannon'\n",
      " 'views' 'chairs' 'seated']\n",
      "\n",
      "Words unique to FALSE class:\n",
      "['bean', 'meats', 'piano', 'ethic', 'lasagna']\n",
      "\n",
      "Words unique to TRUE class:\n",
      "['gently', 'offered', 'gannon', 'views', 'chairs']\n"
     ]
    }
   ],
   "source": [
    "print('MODEL 1')\n",
    "false_class_prob_sorted = MyModel1.feature_log_prob_[0, :].argsort()[::-1]\n",
    "true_class_prob_sorted = MyModel1.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print('Features for FALSE class:')\n",
    "false_class = np.take(MyLieCV.get_feature_names_out(), false_class_prob_sorted[:10])\n",
    "print(false_class)\n",
    "print('\\nFeatures for TRUE class:')\n",
    "true_class = np.take(MyLieCV.get_feature_names_out(), true_class_prob_sorted[:10])\n",
    "print(true_class)\n",
    "\n",
    "unique_false_words = []\n",
    "for word in false_class:\n",
    "    if word not in true_class:\n",
    "        unique_false_words.append(word)\n",
    "print('\\nWords unique to FALSE class:')\n",
    "print(unique_false_words)\n",
    "\n",
    "unique_true_words = []\n",
    "for word in true_class:\n",
    "    if word not in false_class:\n",
    "        unique_true_words.append(word)\n",
    "print('\\nWords unique to TRUE class:')\n",
    "print(unique_true_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1813dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 2\n",
      "Features for FALSE class:\n",
      "['flavor' 'regrettably' 'gives' 'bean' 'seated' 'meats' 'classic' 'ethic'\n",
      " 'warmly' 'gently']\n",
      "\n",
      "Features for TRUE class:\n",
      "['regrettably' 'flavor' 'perplexing' 'gently' 'named' 'einstein'\n",
      " 'perfection' 'terrific' 'pasta' 'veggie']\n",
      "\n",
      "Words unique to FALSE class:\n",
      "['gives', 'bean', 'seated', 'meats', 'classic', 'ethic', 'warmly']\n",
      "\n",
      "Words unique to TRUE class:\n",
      "['perplexing', 'named', 'einstein', 'perfection', 'terrific', 'pasta', 'veggie']\n"
     ]
    }
   ],
   "source": [
    "print('MODEL 2')\n",
    "false_class_prob_sorted = MyModel2.feature_log_prob_[0, :].argsort()[::-1]\n",
    "true_class_prob_sorted = MyModel2.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print('Features for FALSE class:')\n",
    "false_class = np.take(MyLieTFIDF.get_feature_names_out(), false_class_prob_sorted[:10])\n",
    "print(false_class)\n",
    "print('\\nFeatures for TRUE class:')\n",
    "true_class = np.take(MyLieTFIDF.get_feature_names_out(), true_class_prob_sorted[:10])\n",
    "print(true_class)\n",
    "\n",
    "unique_false_words = []\n",
    "for word in false_class:\n",
    "    if word not in true_class:\n",
    "        unique_false_words.append(word)\n",
    "print('\\nWords unique to FALSE class:')\n",
    "print(unique_false_words)\n",
    "\n",
    "unique_true_words = []\n",
    "for word in true_class:\n",
    "    if word not in false_class:\n",
    "        unique_true_words.append(word)\n",
    "print('\\nWords unique to TRUE class:')\n",
    "print(unique_true_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1667f6d9",
   "metadata": {},
   "source": [
    "### Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8137fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 3\n",
      "Features for NEGATIVE class:\n",
      "['flavor' 'regrettably' 'perplexing' 'warmly' 'meats' 'offered' 'gently'\n",
      " 'offer' 'talking' 'lasagna']\n",
      "\n",
      "Features for POSITIVE class:\n",
      "['flavor' 'regrettably' 'bean' 'gently' 'add' 'gives' 'seated' 'safe'\n",
      " 'perplexing' 'quiet']\n",
      "\n",
      "Words unique to NEGATIVE class:\n",
      "['warmly', 'meats', 'offered', 'offer', 'talking', 'lasagna']\n",
      "\n",
      "Words unique to POSITIVE class:\n",
      "['bean', 'add', 'gives', 'seated', 'safe', 'quiet']\n"
     ]
    }
   ],
   "source": [
    "print('MODEL 3')\n",
    "neg_class_prob_sorted = MyModel3.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = MyModel3.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print('Features for NEGATIVE class:')\n",
    "neg_class = np.take(MySentCV.get_feature_names_out(), neg_class_prob_sorted[:10])\n",
    "print(neg_class)\n",
    "print('\\nFeatures for POSITIVE class:')\n",
    "pos_class = np.take(MySentCV.get_feature_names_out(), pos_class_prob_sorted[:10])\n",
    "print(pos_class)\n",
    "\n",
    "unique_neg_words = []\n",
    "for word in neg_class:\n",
    "    if word not in pos_class:\n",
    "        unique_neg_words.append(word)\n",
    "print('\\nWords unique to NEGATIVE class:')\n",
    "print(unique_neg_words)\n",
    "\n",
    "unique_pos_words = []\n",
    "for word in pos_class:\n",
    "    if word not in neg_class:\n",
    "        unique_pos_words.append(word)\n",
    "print('\\nWords unique to POSITIVE class:')\n",
    "print(unique_pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5748c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 4\n",
      "Features for NEGATIVE class:\n",
      "['flavor' 'regrettably' 'perplexing' 'meats' 'dirty' 'warmly' 'perfection'\n",
      " 'romantic' 'seated' 'lasagna']\n",
      "\n",
      "Features for POSITIVE class:\n",
      "['flavor' 'bean' 'gives' 'regrettably' 'flute' 'followed' 'add' 'quiet'\n",
      " 'perplexing' 'gently']\n",
      "\n",
      "Words unique to NEGATIVE class:\n",
      "['meats', 'dirty', 'warmly', 'perfection', 'romantic', 'seated', 'lasagna']\n",
      "\n",
      "Words unique to POSITIVE class:\n",
      "['bean', 'gives', 'flute', 'followed', 'add', 'quiet', 'gently']\n"
     ]
    }
   ],
   "source": [
    "print('MODEL 4')\n",
    "neg_class_prob_sorted = MyModel4.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = MyModel4.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print('Features for NEGATIVE class:')\n",
    "neg_class = np.take(MySentTFIDF.get_feature_names_out(), neg_class_prob_sorted[:10])\n",
    "print(neg_class)\n",
    "print('\\nFeatures for POSITIVE class:')\n",
    "pos_class = np.take(MySentTFIDF.get_feature_names_out(), pos_class_prob_sorted[:10])\n",
    "print(pos_class)\n",
    "\n",
    "unique_neg_words = []\n",
    "for word in neg_class:\n",
    "    if word not in pos_class:\n",
    "        unique_neg_words.append(word)\n",
    "print('\\nWords unique to NEGATIVE class:')\n",
    "print(unique_neg_words)\n",
    "\n",
    "unique_pos_words = []\n",
    "for word in pos_class:\n",
    "    if word not in neg_class:\n",
    "        unique_pos_words.append(word)\n",
    "print('\\nWords unique to POSITIVE class:')\n",
    "print(unique_pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf8ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
